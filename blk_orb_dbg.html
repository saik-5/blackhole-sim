<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />
    <title>Black Hole Ray Tracer - WebGPU</title>
    <style>
        html,
        body {
            margin: 0;
            height: 100%;
            overflow: hidden;
            background: #000;
            font-family: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            touch-action: none;
        }

        #app {
            width: 100%;
            height: 100%;
        }

        /* .hint styles removed */

        .loader {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: #000;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            color: white;
            z-index: 20;
            transition: opacity 0.5s;
        }

        .error {
            color: #ff6b6b;
            max-width: 600px;
            padding: 20px;
            text-align: center;
            line-height: 1.6;
        }

        .error a {
            color: #4fd1c5;
        }

        /* GPU stats styles removed */

        /* Star label styles removed */

        .log-button {
            margin-top: 10px;
            padding: 6px 12px;
            background: rgba(79, 209, 197, 0.2);
            border: 1px solid #4fd1c5;
            color: #4fd1c5;
            border-radius: 4px;
            cursor: pointer;
            font-size: 11px;
            width: 100%;
            transition: all 0.2s;
        }

        .log-button:hover {
            background: rgba(79, 209, 197, 0.3);
        }

        .log-button:active {
            transform: scale(0.98);
        }
    </style>
</head>

<body>
    <div class="loader" id="loader">
        <div>Initializing WebGPU...</div>
        <div style="font-size: 12px; opacity: 0.6; margin-top: 10px;">Optimized for M3 Pro</div>
    </div>
    <div id="app"></div>

    <!-- GPU Stats Panel Removed -->

    <!-- Hint box removed -->

    <script type="module">
        const mount = document.getElementById("app");
        const loader = document.getElementById("loader");
        const statusEl = null; // Removed
        const zoomEl = null;   // Removed
        // Star status elements removed

        // GPU Stats elements - using let so they can be reassigned by createGUI
        // Stats elements removed

        // =====================================================
        // DEBUG LOGGER - Writes all logs to file via WebSocket
        // =====================================================
        class DebugLogger {
            constructor() {
                this.ws = null;
                this.buffer = [];
                this.connected = false;
                this.frameLogCount = 0;
                this.maxFrameLogs = 300; // Limit frame logs to prevent spam
                this.startTime = performance.now();
                this.connect();
            }

            connect() {
                try {
                    this.ws = new WebSocket('ws://localhost:8766');
                    this.ws.onopen = () => {
                        this.connected = true;
                        this.log('INFO', '='.repeat(60));
                        this.log('INFO', 'DEBUG SESSION STARTED');
                        this.log('INFO', `Timestamp: ${new Date().toISOString()}`);
                        this.log('INFO', `User Agent: ${navigator.userAgent}`);
                        this.log('INFO', `Window Size: ${window.innerWidth}x${window.innerHeight}`);
                        this.log('INFO', `Device Pixel Ratio: ${window.devicePixelRatio}`);
                        this.log('INFO', '='.repeat(60));
                        // Flush buffer
                        this.buffer.forEach(msg => this.ws.send(msg));
                        this.buffer = [];
                    };
                    this.ws.onerror = (e) => {
                        console.warn('Debug logger WebSocket error - logs will only go to console');
                    };
                    this.ws.onclose = () => {
                        this.connected = false;
                    };
                } catch (e) {
                    console.warn('Debug logger failed to connect:', e);
                }
            }

            log(level, message, data = null) {
                const elapsed = ((performance.now() - this.startTime) / 1000).toFixed(3);
                let logLine = `[${elapsed}s] [${level}] ${message}`;
                if (data !== null) {
                    try {
                        logLine += ` | DATA: ${JSON.stringify(data)}`;
                    } catch (e) {
                        logLine += ` | DATA: [unserializable]`;
                    }
                }

                // Always log to console too
                const consoleMethod = level === 'ERROR' ? 'error' : level === 'WARN' ? 'warn' : 'log';
                console[consoleMethod](`[DBG] ${logLine}`);

                // Send to server
                if (this.connected && this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(logLine);
                } else {
                    this.buffer.push(logLine);
                }
            }

            info(msg, data = null) { this.log('INFO', msg, data); }
            warn(msg, data = null) { this.log('WARN', msg, data); }
            error(msg, data = null) { this.log('ERROR', msg, data); }

            // Special method for frame logging with limits
            frame(msg, data = null) {
                if (this.frameLogCount < this.maxFrameLogs) {
                    this.log('FRAME', msg, data);
                    this.frameLogCount++;
                } else if (this.frameLogCount === this.maxFrameLogs) {
                    this.log('INFO', `Frame logging limit (${this.maxFrameLogs}) reached, stopping frame logs...`);
                    this.frameLogCount++;
                }
            }

            gpu(msg, data = null) { this.log('GPU', msg, data); }
            capture(msg, data = null) { this.log('CAPTURE', msg, data); }
            memory(msg, data = null) { this.log('MEMORY', msg, data); }
        }

        // Create global debug logger
        const dbg = new DebugLogger();
        window.dbg = dbg; // Make accessible globally for debugging

        // Override console.error to also log to file
        const originalConsoleError = console.error;
        console.error = function (...args) {
            originalConsoleError.apply(console, args);
            const safe = args.map(a => {
                if (typeof a !== 'object' || a === null) return String(a);
                try { return JSON.stringify(a); } catch { return '[unserializable object]'; }
            }).join(' ');
            dbg.error(safe);
        };

        // Catch unhandled errors
        window.addEventListener('error', (event) => {
            dbg.error(`UNCAUGHT ERROR: ${event.message}`, {
                filename: event.filename,
                lineno: event.lineno,
                colno: event.colno,
                error: event.error?.stack || event.error
            });
        });

        window.addEventListener('unhandledrejection', (event) => {
            dbg.error(`UNHANDLED PROMISE REJECTION: ${event.reason}`, {
                reason: event.reason?.stack || event.reason
            });
        });

        // Log memory usage periodically
        setInterval(() => {
            if (performance.memory) {
                dbg.memory('Memory stats', {
                    usedJSHeapSize: (performance.memory.usedJSHeapSize / 1024 / 1024).toFixed(2) + ' MB',
                    totalJSHeapSize: (performance.memory.totalJSHeapSize / 1024 / 1024).toFixed(2) + ' MB',
                    jsHeapSizeLimit: (performance.memory.jsHeapSizeLimit / 1024 / 1024).toFixed(2) + ' MB'
                });
            }
        }, 5000);

        dbg.info('Debug logger initialized');

        // Check WebGPU support immediately
        if (!navigator.gpu) {
            loader.innerHTML = `
        <div class="error">
          <h2>WebGPU Not Supported</h2>
          <p>Your browser doesn't support WebGPU yet.</p>
          <p><strong>For M3 Pro Mac:</strong></p>
          <ul style="text-align: left; display: inline-block;">
            <li>Use Chrome 113+ or Edge 113+</li>
            <li>Safari: Enable in Develop menu → Feature Flags → WebGPU</li>
          </ul>
          <p style="margin-top: 20px;">
            <a href="?webgl">Try WebGL version instead</a>
          </p>
        </div>
      `;
            throw new Error("WebGPU not supported");
        }

        const params = {
            rs: 1.0,              // Schwarzschild radius
            rin: 1.90,            // inner disk radius
            rout: 12.0,           // outer disk radius
            maxSteps: 300,        // integration steps (Balanced quality/performance)
            dPhi: 0.04,           // step in polar angle (Optimized)
            escapeR: 10000.0,     // "infinity" radius (Increased for zoom)
            diskBoost: 4.0,       // brightness multiplier
            debugView: 0,         // 0=normal, 1=uv, 2=ray dir
            // S2 (single-star prototype) - removed
            starSize: 1.0,        // world radius for physical star
            starBoost: 6.0,       // brightness multiplier
            screenOrbitRadius: 0.35, // fixed screen-space orbit radius (NDC units, 0-1). Zoom-independent.
            vsync: true,          // Frame pacing: true=FIFO (smooth), false=Immediate (low latency)
        };

        // --- Single Star: S2 (from your Wikipedia table) ---
        // Angles in degrees, times in years.
        // We'll compute a 3D position and pass the *direction* to the shader; lensing happens automatically
        // because starfield() is sampled at the ray’s asymptotic direction.
        const STAR_S2 = {
            name: 'S2',
            // Use physical scale (AU) only to keep the orbit outside the disk if we later render finite distance.
            // For direction-only starfield, the absolute scale cancels.
            a_AU: 0.1251 * 8178,        // arcsec -> AU using ~8178 pc distance (1" ≈ 8178 AU)
            e: 0.8843,
            i_deg: 133.91,
            Omega_deg: 228.07,
            omega_deg: 66.25,
            Tp_year: 2018.379,
            P_year: 16.0518,
            color: [0.70, 0.85, 1.00],  // Bright blue-white (white star look)
        };

        // S55 star - GRAVITY Collaboration orbital elements
        // Shorter period (~12.2 yr), less eccentric, different orbital plane
        const STAR_S55 = {
            name: 'S55',
            a_AU: 0.10424 * 8275.9,     // arcsec -> AU using R0 = 8275.9 pc
            e: 0.72980,
            i_deg: 159.59,
            Omega_deg: 319.43,
            omega_deg: 327.77,
            Tp_year: 2009.4738,
            P_year: 12.22,              // Derived from Kepler's law
            color: [0.95, 0.60, 0.20],  // Orange star
        };

        // S38 star - GRAVITY Collaboration orbital elements
        // Period ~19.5 yr, high eccentricity, different orbital plane
        const STAR_S38 = {
            name: 'S38',
            a_AU: 0.14249 * 8275.9,     // arcsec -> AU using R0 = 8275.9 pc
            e: 0.81807,
            i_deg: 168.69,
            Omega_deg: 122.43,
            omega_deg: 40.065,
            Tp_year: 2022.6843,
            P_year: 19.53,              // Derived from Kepler's law
            color: [0.75, 0.30, 0.95],  // Purple/violet star
        };

        // S29 star - GRAVITY Collaboration orbital elements
        // Extreme long period (~88.5 yr), very high eccentricity, closest pericenter
        const STAR_S29 = {
            name: 'S29',
            a_AU: 0.39025 * 8275.9,     // arcsec -> AU using R0 = 8275.9 pc
            e: 0.96880,                 // Extremely eccentric!
            i_deg: 144.24,
            Omega_deg: 4.9259,
            omega_deg: 203.68,
            Tp_year: 2021.4102,
            P_year: 88.52,              // Very long period
            color: [0.20, 0.95, 0.30],  // Green star
        };

        // S4716 star - Peissker et al. (2022)
        // Shortest period (~4.0 yr), e=0.756
        // Angles are representative approximations for valid visualization
        const STAR_S4716 = {
            name: 'S4716',
            a_AU: 411.0,                // Derived from P=4.02yr
            e: 0.756,
            i_deg: 70.0,                // Visual approximation
            Omega_deg: 10.0,            // Visual approximation
            omega_deg: 300.0,           // Visual approximation
            Tp_year: 2022.5,
            P_year: 4.02,
            color: [1.0, 0.2, 0.6],     // Hot pink star
        };

        // Orbit math (Keplerian)
        const TAU = Math.PI * 2;
        function wrapTau(x) {
            x %= TAU;
            return x < 0 ? x + TAU : x;
        }

        function solveKepler(M, e) {
            // Solve E - e sin(E) = M
            let E = e < 0.8 ? M : Math.PI; // decent starting guess
            for (let k = 0; k < 12; k++) {
                const f = E - e * Math.sin(E) - M;
                const fp = 1 - e * Math.cos(E);
                E -= f / fp;
            }
            return E;
        }

        function orbitalPosition3D(star, year) {
            const n = TAU / star.P_year;
            const M = wrapTau(n * (year - star.Tp_year));
            const E = solveKepler(M, star.e);
            const cosE = Math.cos(E);
            const sinE = Math.sin(E);
            const r = star.a_AU * (1 - star.e * cosE);

            // True anomaly
            const nu = 2 * Math.atan2(
                Math.sqrt(1 + star.e) * Math.sin(E / 2),
                Math.sqrt(1 - star.e) * Math.cos(E / 2)
            );

            // Position in orbital plane (periapsis along +x')
            const xP = r * Math.cos(nu);
            const yP = r * Math.sin(nu);

            // Rotate: Rz(Ω) * Rx(i) * Rz(ω)
            const Ω = star.Omega_deg * Math.PI / 180;
            const i = star.i_deg * Math.PI / 180;
            const ω = star.omega_deg * Math.PI / 180;

            const cosΩ = Math.cos(Ω), sinΩ = Math.sin(Ω);
            const cosi = Math.cos(i), sini = Math.sin(i);
            const cosω = Math.cos(ω), sinω = Math.sin(ω);

            // First Rz(ω)
            const x1 = xP * cosω - yP * sinω;
            const y1 = xP * sinω + yP * cosω;
            const z1 = 0;

            // Then Rx(i)
            const x2 = x1;
            const y2 = y1 * cosi - z1 * sini;
            const z2 = y1 * sini + z1 * cosi;

            // Then Rz(Ω)
            const x3 = x2 * cosΩ - y2 * sinΩ;
            const y3 = x2 * sinΩ + y2 * cosΩ;
            const z3 = z2;

            return { x: x3, y: y3, z: z3 };
        }

        function normalize3(x, y, z) {
            const L = Math.hypot(x, y, z) || 1;
            return { x: x / L, y: y / L, z: z / L };
        }

        // Get the orbital phase angle (true anomaly + argument of periapsis) for screen-space orbit
        function getOrbitalPhase(star, year) {
            const n = TAU / star.P_year;
            const M = wrapTau(n * (year - star.Tp_year));
            const E = solveKepler(M, star.e);
            const nu = 2 * Math.atan2(
                Math.sqrt(1 + star.e) * Math.sin(E / 2),
                Math.sqrt(1 - star.e) * Math.cos(E / 2)
            );
            // Include argument of periapsis so the orbit orientation is preserved
            return nu + (star.omega_deg * Math.PI / 180);
        }

        function clamp01(v) {
            return Math.max(0, Math.min(1, v));
        }

        // updateS2Label removed

        // Zoom slider helpers (log scale for usable precision at both near/far distances)
        // Zoom slider helpers (log scale for usable precision at both near/far distances)
        const ZOOM_MIN = 0.1;
        const ZOOM_MAX = 5000;
        const ZOOM_LOG_DEN = Math.log(ZOOM_MAX / ZOOM_MIN);

        function zoomTFromDistance(distance) {
            const d = Math.max(ZOOM_MIN, Math.min(ZOOM_MAX, distance));
            return Math.log(d / ZOOM_MIN) / ZOOM_LOG_DEN; // 0..1
        }

        function zoomDistanceFromT(t) {
            const tt = Math.max(0, Math.min(1, t));
            return ZOOM_MIN * Math.exp(ZOOM_LOG_DEN * tt);
        }

        function findBestAlignmentYear(star, camForward, startYear) {
            // Pick an epoch where the star direction is closest to the camera forward direction
            // so you see a strong lensing configuration immediately.
            const samples = 360;
            let bestYear = startYear;
            let bestDot = -1;

            for (let k = 0; k < samples; k++) {
                const t = (k / samples) * star.P_year;
                const year = startYear + t;
                const p = orbitalPosition3D(star, year);
                const d = normalize3(p.x, p.y, p.z);
                const dot = d.x * camForward.x + d.y * camForward.y + d.z * camForward.z;
                if (dot > bestDot) {
                    bestDot = dot;
                    bestYear = year;
                }
            }

            return bestYear;
        }

        class WebGPUBlackHole {
            constructor(canvas) {
                this.canvas = canvas;
                this.device = null;
                this.context = null;
                this.pipeline = null;
                this.uniformBuffer = null;
                this.bindGroup = null;

                // Camera state - edge-on view of accretion disk (classic "Interstellar" view)
                // Default Pos: 0.1, 0.2, 0.0 (requested by user)
                // r ~= 0.1, phi ~= 1.47, theta = 0
                this.cameraPos = { x: 0.1, y: 0.2, z: 0.0 };
                this.cameraRot = { theta: 0.0, phi: 1.47 };
                this.cameraDistance = 0.1;

                // Cinematic State (single-clock for realtime + offline)
                this.cinematicMode = false;
                this.cinematicElapsed = 0;
                this._forceZeroDtNextFrame = false;

                // Segment-based slow-motion: allocate more seconds to specific parts
                //this.cinematicSegments = [
                //    { seconds: 40, from: 0.00, to: 0.30, ease: 'smooth' },
                //    { seconds: 20, from: 0.30, to: 0.60, ease: 'linear' }, // middle section
                //    { seconds: 20, from: 0.60, to: 1.00, ease: 'linear' },
                //];

                this.cinematicSegments = [
                    { seconds: 40, from: 0.00, to: 0.35, ease: 'linear' },
                    { seconds: 20, from: 0.35, to: 1.00, ease: 'linear' },
                    //{ seconds: 20, from: 0.30, to: 0.60, ease: 'linear' }, // middle section
                    //{ seconds: 20, from: 0.60, to: 1.00, ease: 'linear' },
                ];

                this.cinematicDuration = this.cinematicSegments.reduce((s, seg) => s + seg.seconds, 0);

                // Cinematic Free Camera State
                this.activeCamera = 'orbit'; // 'orbit' or 'free'
                this.freeCamera = {
                    pos: { x: 0, y: 0, z: 20 },
                    rot: { yaw: -Math.PI / 2, pitch: 0 }, // yaw -PI/2 looks at 0,0,0 from +Z
                    speed: 0.5,
                    keys: { w: false, a: false, s: false, d: false, q: false, e: false, shift: false }
                };

                // Interaction state
                this.isDragging = false;
                this.lastMouseX = 0;
                this.lastMouseY = 0;

                // UI refs (wired up in createGUI)
                this.zoomSlider = null;
                this.zoomValueEl = null;

                this.time = 0;
                this.frameCount = 0;
                this.lastFPSUpdate = performance.now();
                this.currentFPS = 0;

                // Performance tracking
                this.frameTimes = [];
                this.lastFrameTime = performance.now();
                this.lastLogTime = performance.now();

                // Recorder State
                this.isRecording = false;
                this.frameNumber = 0;
                this.ws = null;

                // GPU Capture buffers (triple buffering) - for legacy PNG capture
                this.stagingBuffers = [];
                this.bufferIndex = 0;
                this.pendingReads = new Set();

                // WebCodecs Video Encoder State (for 4K 60fps H.264 capture)
                this.videoEncoder = null;
                this.videoChunks = [];
                this.videoRecordingStart = 0;
                this.useWebCodecs = true; // Use WebCodecs by default (much faster)

                // Offline Deterministic Recording State
                this.isOfflineRendering = false;
                this._offlineBusy = false; // Flag for offline PNG rendering

                // Offline PNG Capture Resources
                this.capturePipeline = null;
                this.captureTexture = null;
                this.captureBuffer = null;
                this.capturePaddedBytesPerRow = 0;
                this.captureBytesPerRow = 0;

                // Reusable 2D canvas for PNG encoding
                this.pngCanvas = null;
                this.pngCtx = null;
                this.pngImageData = null;

                // Stored references for capture pipeline creation
                this.shaderModule = null;
                this.bindGroupLayout = null;

                // Orbit simulation time (years) status: Removed
                // this.simYear = 2018.379; // Logic removed

                // Pick an initial epoch where S2 is close to the camera forward direction
                // (strong lensing configuration right away).
                this.updateCamera();

                // Sync free cam start pos to orbit cam
                // Pre-allocate Uniform Buffer Data (avoiding per-frame GC)
                // 80 floats = 320 bytes
                this.uniformData = new ArrayBuffer(80 * 4);
                this.uF32 = new Float32Array(this.uniformData);
                this.uI32 = new Int32Array(this.uniformData);

                // Pre-allocate temporary vectors to reduce GC churn
                this.vecFwd = new Float32Array(3);
                this.vecRight = new Float32Array(3);
                this.vecUp = new Float32Array(3);
                this.vecPos = new Float32Array(3);

                // Cached orbital positions (since simYear is now static)
                this.cachedStarPositions = false;

                // Timeline state for refresh-rate independent simulation
                this._simStartNow = null;
                this._simFrame = 0;

                // Dirty flags
                this.uniformsDirty = true;
            }

            async init() {
                dbg.gpu('=== WebGPU INITIALIZATION STARTING ===');

                // Get GPU adapter and device
                dbg.gpu('Requesting WebGPU Adapter (High Performance)...');
                let adapter = await navigator.gpu.requestAdapter({
                    powerPreference: 'high-performance'
                });

                // Fallback: Try default/low-power if high-perf failed (e.g. driver blacklist)
                if (!adapter) {
                    dbg.warn('High-performance adapter not found. Trying default adapter...');
                    adapter = await navigator.gpu.requestAdapter();
                }

                if (!adapter) {
                    const msg = "WebGPU initialization failed: No GPU adapter found. Your browser may have blacklisted the GPU due to a previous crash. Please RESTART the browser completely.";
                    dbg.error(msg);
                    alert(msg); // Visible alert for the user
                    throw new Error(msg);
                }

                dbg.gpu('Adapter acquired successfully');

                // Log adapter info
                const adapterInfo = await adapter.requestAdapterInfo?.() || {};
                dbg.gpu('Adapter Info', {
                    vendor: adapterInfo.vendor || 'unknown',
                    architecture: adapterInfo.architecture || 'unknown',
                    device: adapterInfo.device || 'unknown',
                    description: adapterInfo.description || 'unknown'
                });

                dbg.gpu('Requesting GPU device...');
                this.device = await adapter.requestDevice();
                dbg.gpu('Device acquired successfully');

                // Surface validation/shader errors that would otherwise fail silently as a black frame.
                this.device.addEventListener?.('uncapturederror', (event) => {
                    dbg.error('WebGPU uncaptured error:', { error: event.error?.message || event.error });
                });

                // Handle device lost
                this.device.lost.then((info) => {
                    dbg.error('GPU DEVICE LOST!', { reason: info.reason, message: info.message });
                });

                // Log GPU info
                dbg.gpu('GPU Features', [...adapter.features]);
                dbg.gpu('GPU Limits (selected)', {
                    maxBufferSize: adapter.limits.maxBufferSize,
                    maxTextureDimension2D: adapter.limits.maxTextureDimension2D,
                    maxBindGroups: adapter.limits.maxBindGroups,
                    maxUniformBufferBindingSize: adapter.limits.maxUniformBufferBindingSize
                });

                // Setup canvas context
                dbg.gpu('Setting up canvas context...');
                this.context = this.canvas.getContext('webgpu');
                const devicePixelRatio = Math.min(window.devicePixelRatio, 2);

                this.canvas.width = this.canvas.clientWidth * devicePixelRatio;
                this.canvas.height = this.canvas.clientHeight * devicePixelRatio;

                dbg.gpu('Canvas size', {
                    width: this.canvas.width,
                    height: this.canvas.height,
                    clientWidth: this.canvas.clientWidth,
                    clientHeight: this.canvas.clientHeight,
                    devicePixelRatio
                });

                const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
                this.presentationFormat = presentationFormat; // Store for capture texture creation
                dbg.gpu('Presentation format', { format: presentationFormat });

                dbg.gpu('Configuring context...');
                this.context.configure({
                    device: this.device,
                    format: presentationFormat,
                    alphaMode: 'premultiplied',
                    presentMode: params.vsync ? 'fifo' : 'immediate',
                });
                dbg.gpu('Context configured');

                dbg.gpu('Creating render pipeline...');
                await this.createPipeline(presentationFormat);
                dbg.gpu('Pipeline created successfully');

                this.setupInteraction();
                dbg.gpu('=== WebGPU INITIALIZATION COMPLETE ===');
            }

            async createPipeline(format) {
                // Shader code in WGSL
                const shaderCode = `
struct Uniforms {
  time: f32,
  rs: f32,
  rin: f32,
  rout: f32,
  maxSteps: i32,
  dPhi: f32,
  escapeR: f32,
  diskBoost: f32,
  starPosX: f32,
  starPosY: f32,
  starPosZ: f32,
  starSize: f32,
  starR: f32,
  starG: f32,
  starB: f32,
  starBoost: f32,
  camPosX: f32,
  camPosY: f32,
  camPosZ: f32,
  camFwdX: f32,
  camFwdY: f32,
  camFwdZ: f32,
  camRightX: f32,
  camRightY: f32,
  camRightZ: f32,
  camUpX: f32,
  camUpY: f32,
  camUpZ: f32,
  tanHalfFov: f32,
  aspect: f32,
  // Star 2 (S55) properties
  star2PosX: f32,
  star2PosY: f32,
  star2PosZ: f32,
  star2Size: f32,
  star2R: f32,
  star2G: f32,
  star2B: f32,
  star2Boost: f32,
  // Star 3 (S38) properties
  star3PosX: f32,
  star3PosY: f32,
  star3PosZ: f32,
  star3Size: f32,
  star3R: f32,
  star3G: f32,
  star3B: f32,
  star3Boost: f32,
  // Star 4 (S29) properties
  star4PosX: f32,
  star4PosY: f32,
  star4PosZ: f32,
  star4Size: f32,
  star4R: f32,
  star4G: f32,
  star4B: f32,
  star4Boost: f32,
  // Star 5 (S4716) properties
  star5PosX: f32,
  star5PosY: f32,
  star5PosZ: f32,
  star5Size: f32,
  star5R: f32,
  star5G: f32,
  star5B: f32,
  star5Boost: f32,
  debugView: f32,
  viewportHeight: f32, // For resolution-aware LOD (replaces hardcoded 800)
  _pad2: f32,
  _pad3: f32,
}

@group(0) @binding(0) var<uniform> u: Uniforms;

struct VertexOutput {
  @builtin(position) position: vec4f,
  @location(0) uv: vec2f,
}

@vertex
fn vertexMain(@builtin(vertex_index) vertexIndex: u32) -> VertexOutput {
  var pos = array<vec2f, 6>(
    vec2f(-1.0, -1.0),
    vec2f(1.0, -1.0),
    vec2f(-1.0, 1.0),
    vec2f(-1.0, 1.0),
    vec2f(1.0, -1.0),
    vec2f(1.0, 1.0)
  );
  
  var output: VertexOutput;
  output.position = vec4f(pos[vertexIndex], 0.0, 1.0);
  output.uv = pos[vertexIndex] * 0.5 + 0.5;
  return output;
}

// Hash function for noise
// Hash function for noise (Canonical sin-dot, stable)
fn hash(p: vec2f) -> f32 {
  return fract(sin(dot(p, vec2f(12.9898, 78.233))) * 43758.5453);
}

// 2D noise
// Raw 2D noise with Quintic interpolation
// Raw 2D noise with Quintic interpolation
fn noiseRaw(p: vec2f) -> f32 {
  let i = floor(p);
  let f = fract(p);
  // Quintic interpolation for smoother derivatives
  let u = f * f * f * (f * (f * 6.0 - 15.0) + 10.0);
  
  return mix(
    mix(hash(i), hash(i + vec2f(1.0, 0.0)), u.x),
    mix(hash(i + vec2f(0.0, 1.0)), hash(i + vec2f(1.0, 1.0)), u.x),
    u.y
  );
}

// Antialiased noise using fwidth
// Antialiased noise using explicit LOD
fn noise(p: vec2f, lod: f32) -> f32 {
  // Fade out high frequencies based on LOD
  // Relaxed threshold: Allow more detail before blurring
  let intensity = 1.0 - smoothstep(1.0, 4.0, lod);
  
  if (intensity < 0.01) { return 0.5; }
  
  return mix(0.5, noiseRaw(p), intensity);
}

// Fractal Brownian Motion for disk texture
// Fractal Brownian Motion for disk texture
// 3D hash for seamless noise
fn hash3(p: vec3f) -> f32 {
  return fract(sin(dot(p, vec3f(12.9898, 78.233, 45.164))) * 43758.5453);
}

// 3D noise
fn noise3D(p: vec3f) -> f32 {
  let i = floor(p);
  let f = fract(p);
  let u = f * f * (3.0 - 2.0 * f);
  
  return mix(
    mix(mix(hash3(i + vec3f(0,0,0)), hash3(i + vec3f(1,0,0)), u.x),
        mix(hash3(i + vec3f(0,1,0)), hash3(i + vec3f(1,1,0)), u.x), u.y),
    mix(mix(hash3(i + vec3f(0,0,1)), hash3(i + vec3f(1,0,1)), u.x),
        mix(hash3(i + vec3f(0,1,1)), hash3(i + vec3f(1,1,1)), u.x), u.y), u.z);
}

// Fractal Brownian Motion for disk texture (Seamless 3D)
// Fractal Brownian Motion for disk texture (Seamless 3D)
fn fbmDisk(p: vec2f, lod: f32) -> f32 {
  // Unpack polar coordinates (r, angle) stored in p
  let r = p.x / 12.0;       // Restore radius approx
  let ang = p.y / 2.0;      // Restore angle approx
  
  // Convert to 3D ring coordinates for seamless wrapping
  // We utilize the 3rd dimension to close the loop
  let ringScale = 2.0;
  var pos3D = vec3f(
     r * 12.0,                  // Radial detail
     cos(ang) * ringScale,      // Loop X
     sin(ang) * ringScale       // Loop Y
  );

  var f = 0.0;
  
  // 3 octaves of 3D noise (Removed 4th octave to prevent aliasing cleanly)
  f += 0.5000 * noise3D(pos3D); pos3D *= 2.02;
  f += 0.2500 * noise3D(pos3D); pos3D *= 2.03;
  f += 0.1250 * noise3D(pos3D); 
  // f += 0.0625 * noise3D(pos3D); // Disabled high freq
  
  return f;
}

// 3D Sphere Hit Test
fn hitSphere(ro: vec3f, rd: vec3f, center: vec3f, radius: f32) -> f32 {
  let oc = ro - center;
  let b = dot(oc, rd);
  let c = dot(oc, oc) - radius * radius;
  let h = b * b - c;
  if (h < 0.0) { return -1.0; }
  return -b - sqrt(h);
}

// 3D Star Surface & Glow (Enhanced with procedural noise and limb darkening)
fn getStarColor(p: vec3f, center: vec3f, radius: f32) -> vec3f {
  let baseCol = vec3f(u.starR, u.starG, u.starB);
  
  // Calculate surface normal and local coordinates
  let surfaceNormal = normalize(p - center);
  
  // Limb darkening: edges appear darker than center
  let viewDir = normalize(vec3f(u.camPosX, u.camPosY, u.camPosZ) - p);
  let limbFactor = dot(surfaceNormal, viewDir);
  let limbDarkening = 0.4 + 0.6 * pow(max(limbFactor, 0.0), 0.6);
  
  // Procedural noise for surface detail (animated churning)
  // Use 3D position on sphere surface for seamless noise
  let noiseScale = 4.0;
  let timeOffset = u.time * 0.15; // Slow churning animation
  
  // Multiple octaves of noise for surface granulation
  var surfaceNoise = 0.0;
  var noisePos = surfaceNormal * noiseScale;
  
  // Animate noise by rotating the sample position over time
  let rotAngle = timeOffset * 0.3;
  let cosR = cos(rotAngle);
  let sinR = sin(rotAngle);
  noisePos = vec3f(
    noisePos.x * cosR - noisePos.z * sinR,
    noisePos.y,
    noisePos.x * sinR + noisePos.z * cosR
  );
  
  // FBM-style noise accumulation
  surfaceNoise += noise3D(noisePos * 1.0 + vec3f(timeOffset * 0.2, 0.0, 0.0)) * 0.5;
  surfaceNoise += noise3D(noisePos * 2.0 + vec3f(0.0, timeOffset * 0.15, 0.0)) * 0.25;
  surfaceNoise += noise3D(noisePos * 4.0 + vec3f(0.0, 0.0, timeOffset * 0.1)) * 0.125;
  
  // Normalize and create surface variation
  let surfaceVariation = 0.7 + surfaceNoise * 0.6; // Range ~0.7 to 1.3
  
  // Add some "hot spots" (brighter granules)
  let hotSpots = smoothstep(0.6, 0.9, surfaceNoise) * 0.4;
  
  // Emissive color mixing (warmer at hot spots)
  let warmTint = vec3f(1.0, 0.95, 0.85); // Slight warm tint
  let coolTint = vec3f(0.9, 0.95, 1.0);  // Slight cool tint
  let colorMix = mix(coolTint, warmTint, surfaceNoise);
  
  // Final star surface color
  let finalColor = baseCol * colorMix * surfaceVariation * limbDarkening;
  
  return (finalColor + hotSpots * baseCol) * u.starBoost;
}

@fragment
fn fragmentMain(input: VertexOutput) -> @location(0) vec4f {
  let ndc = input.uv * 2.0 - 1.0;
  
  let camPos = vec3f(u.camPosX, u.camPosY, u.camPosZ);
  let camFwd = vec3f(u.camFwdX, u.camFwdY, u.camFwdZ);
  let camRight = vec3f(u.camRightX, u.camRightY, u.camRightZ);
  let camUp = vec3f(u.camUpX, u.camUpY, u.camUpZ);
  
  let rd = normalize(
    camFwd +
    camRight * (ndc.x * u.tanHalfFov * u.aspect) +
    camUp * (ndc.y * u.tanHalfFov)
  );
  let ro = camPos;

  // Debug views (press 'D' to cycle)
  let dbg = i32(u.debugView + 0.5);
  if (dbg == 1) {
    return vec4f(input.uv, 0.0, 1.0);
  }
  if (dbg == 2) {
    return vec4f(rd * 0.5 + vec3f(0.5), 1.0);
  }
  
  // Star positions
  let starPos = vec3f(u.starPosX, u.starPosY, u.starPosZ);
  let star2Pos = vec3f(u.star2PosX, u.star2PosY, u.star2PosZ);
  let star3Pos = vec3f(u.star3PosX, u.star3PosY, u.star3PosZ);
  let star4Pos = vec3f(u.star4PosX, u.star4PosY, u.star4PosZ);
  let star5Pos = vec3f(u.star5PosX, u.star5PosY, u.star5PosZ);

  // Compute angular momentum (stable even when the ray looks straight at the origin)
  let L = cross(ro, rd);
  let b = length(L);
  var Lhat = normalize(L);
  if (b < 1e-5) {
    // If the impact parameter is almost zero, pick a fallback plane that is
    // still orthogonal to the camera position to avoid degeneracy.
    let alt = cross(ro, vec3f(0.0, 1.0, 0.0));
    let altLen = length(alt);
    if (altLen < 1e-5) {
      Lhat = normalize(cross(ro, vec3f(1.0, 0.0, 0.0)));
    } else {
      Lhat = alt / altLen;
    }
  }

  // Orthonormal basis in orbital plane
  let e1 = normalize(ro - Lhat * dot(ro, Lhat));
  let e2 = cross(Lhat, e1);

  let r0 = length(ro);
  var u_orbit = 1.0 / max(r0, 1e-6);

  let dproj = normalize(rd - Lhat * dot(rd, Lhat));
  let vr = dot(dproj, e1);
  let vt = max(dot(dproj, e2), 1e-4);

  var w = -u_orbit * vr / vt;
  // var phi = 0.0; // Optimized out
  
  // Pre-compute rotation sine/cosine for dPhi (constant optimization)
  let cd = cos(u.dPhi); 
  let sd = sin(u.dPhi); 
  
  // Initial basis rotation state (starts at phi=0 => cos=1, sin=0)
  var c_phi = 1.0;
  var s_phi = 0.0;

  var pPrev = ro;
  var p = ro;
  // We treat the disk as emissive-but-not-fully-opaque so background stars remain visible.
  // This also makes it much easier to see the star during its orbit.
  var done = false;
  var hitType = 0; // 0=none, 1=event, 2=disk (any), 3=escape
  var didHitDisk = false;
  var trans = 1.0;
  var accum = vec3f(0.0);
  var bg = vec3f(0.0);

  // Geodesic integration (RK4)
  for (var it = 0; it < u.maxSteps; it++) {
    let h = u.dPhi;
    
    // RK4 Integration
    let k1u = w;
    let k1w = 1.5 * u.rs * u_orbit * u_orbit - u_orbit;
    
    let u2 = u_orbit + 0.5 * h * k1u;
    let w2 = w + 0.5 * h * k1w;
    let k2u = w2;
    let k2w = 1.5 * u.rs * u2 * u2 - u2;
    
    let u3 = u_orbit + 0.5 * h * k2u;
    let w3 = w + 0.5 * h * k2w;
    let k3u = w3;
    let k3w = 1.5 * u.rs * u3 * u3 - u3;
    
    let u4 = u_orbit + h * k3u;
    let w4 = w + h * k3w;
    let k4u = w4;
    let k4w = 1.5 * u.rs * u4 * u4 - u4;

    u_orbit += (h / 6.0) * (k1u + 2.0 * k2u + 2.0 * k3u + k4u);
    w += (h / 6.0) * (k1w + 2.0 * k2w + 2.0 * k3w + k4w);
    // phi += h; // Removed

    let r = 1.0 / max(u_orbit, 1e-6);

    pPrev = p;
    // p = (e1 * cos(phi) + e2 * sin(phi)) * r; // Old
    
    // Incremental rotation: 
    // new_c = c*cd - s*sd
    // new_s = s*cd + c*sd
    let c_next = c_phi * cd - s_phi * sd;
    let s_next = s_phi * cd + c_phi * sd;
    c_phi = c_next;
    s_phi = s_next;
    
    p = (e1 * c_phi + e2 * s_phi) * r;
    
    // Star S2 removed

    // Star S55 removed

    // Star S38 removed

    // Star S29 removed

    // Star S4716 removed

    // Hit event horizon
    if (r < u.rs * 1.001) {
      done = true;
      hitType = 1;
      break;
    }

    // Escaped to infinity
    if (r > u.escapeR) {
      done = true;
      // Background is black
      bg = vec3f(0.0);
      hitType = 3;
      break;
    }

    // Check disk intersection
    let y0 = pPrev.y;
    let y1 = p.y;
    
    if (y0 * y1 < 0.0) {
      let t = y0 / (y0 - y1);
      let phit = mix(pPrev, p, t);
      let rr = length(vec2f(phit.x, phit.z));




      if (rr > u.rin && rr < u.rout && !didHitDisk) {
        // Filamentous disk texture
        let ang = atan2(phit.z, phit.x);
        let speed = 6.0 / sqrt(rr);
        let rotAngle = ang + u.time * speed * 0.2;

        // Calculate LOD based on distance and resolution
        let dist = length(phit - camPos);
        // Standard distance-based filtering (Reverted aggressive grazing blur)
        let pixelSize = (u.tanHalfFov * dist * 2.0) / u.viewportHeight;
        let texLOD = pixelSize * 40.0; 

        let noiseUV = vec2f(rr * 12.0, rotAngle * 2.0);
        let n = fbmDisk(noiseUV, texLOD);
        
        var filaments = smoothstep(0.2, 0.8, n);
        let detail = noise(vec2f(rr * 40.0, rotAngle * 4.0), texLOD * 3.0);
        filaments += detail * 0.2;

        // NOTE: smoothstep(edge0, edge1, x) is undefined if edge0 >= edge1 on some implementations.
        // Use a well-defined outer falloff: 1.0 inside, fades to 0.0 approaching/outside u.rout.
        let alphaInner = smoothstep(u.rin, u.rin + 1.0, rr);
        let alphaOuter = 1.0 - smoothstep(u.rout - 4.0, u.rout, rr);
        let alpha = alphaInner * alphaOuter;

        // Blackbody color
        // let temp = pow(u.rin / rr, 1.5);
        let invR = u.rin / rr;
        let temp = invR * sqrt(invR);
        
        let blackbody = mix(
          vec3f(0.8, 0.1, 0.01),
          vec3f(1.0, 0.9, 0.8),
          clamp(temp, 0.0, 1.0)
        );

        // Doppler beaming
        let vdir = normalize(vec3f(-phit.z, 0.0, phit.x));
        let vmag = min(sqrt(u.rs / (2.0 * rr)), 0.7);
        let rayDirAtHit = normalize(p - pPrev);
        let mu = dot(vdir, -rayDirAtHit);
        let gamma = 1.0 / sqrt(1.0 - vmag * vmag);
        let doppler = 1.0 / (gamma * (1.0 - vmag * mu));
        // let beaming = pow(max(doppler, 0.0), 3.0);
        let beamBase = max(doppler, 0.0);
        let beaming = beamBase * beamBase * beamBase;

        // Emissive disk contribution + simple transparency so background stars show through.
        // Opacity is intentionally capped for a nice look.
        let diskCol = blackbody * filaments * beaming * u.diskBoost;
        let diskOpacity = clamp(alpha * 0.65, 0.0, 0.85);

        accum += diskCol * diskOpacity * trans;
        trans *= (1.0 - diskOpacity);

        didHitDisk = true;
        hitType = 2;

        // Early-out if we’re basically opaque.
        if (trans < 0.02) {
          done = true;
          break;
        }


      }
    }
  }

    // "Orphaned" rays that run out of steps but didn't escape
    // will just leave 'bg' as 0.0 (black), effectively merging with the shadow.
    // The previous bug was here: calling starfield() on !done created garbage noise inside the shadow.

  let col = accum + bg * trans;

  if (dbg == 3) {
    // Hit classification debug: disk=yellow, event=red, escape=blue, none=green
    if (hitType == 2) { return vec4f(vec3f(1.0, 1.0, 0.0) * (0.25 + 0.75 * clamp(length(col), 0.0, 1.0)), 1.0); }
    if (hitType == 1) { return vec4f(1.0, 0.0, 0.0, 1.0); }
    if (hitType == 3) { return vec4f(0.1, 0.3, 1.0, 1.0); }
    if (hitType == 5) { return vec4f(1.0, 1.0, 1.0, 1.0); } // Star hit
    return vec4f(0.0, 0.6, 0.2, 1.0);
  }

  return vec4f(col, 1.0);
}
`;

                const shaderModule = this.device.createShaderModule({
                    code: shaderCode,
                    label: 'Black Hole Shader'
                });

                // Store for capture pipeline creation
                this.shaderModule = shaderModule;

                // Print WGSL compilation messages (super helpful when the screen is black).
                if (shaderModule.getCompilationInfo) {
                    shaderModule.getCompilationInfo().then((info) => {
                        const msgs = info.messages || [];
                        const errCount = msgs.filter(m => m.type === 'error').length;
                        if (msgs.length) {
                            console.groupCollapsed(`WGSL compilation messages (${errCount} errors)`);
                            for (const m of msgs) console.log(m.type.toUpperCase(), m.lineNum, m.linePos, m.message);
                            console.groupEnd();
                        }
                    }).catch(() => { /* ignore */ });
                }

                // Create uniform buffer
                // NOTE: Keep this in sync with the Uniforms struct layout in WGSL.
                // We allocate 80 floats (320 bytes) to include all five stars + padding.
                const uniformBufferSize = 80 * 4; // 80 x f32 bytes (some slots used as i32 views)
                this.uniformBuffer = this.device.createBuffer({
                    size: uniformBufferSize,
                    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
                });

                // Create bind group layout and bind group
                const bindGroupLayout = this.device.createBindGroupLayout({
                    entries: [{
                        binding: 0,
                        visibility: GPUShaderStage.FRAGMENT,
                        buffer: { type: 'uniform' }
                    }]
                });

                // Store for capture pipeline creation
                this.bindGroupLayout = bindGroupLayout;

                this.bindGroup = this.device.createBindGroup({
                    layout: bindGroupLayout,
                    entries: [{
                        binding: 0,
                        resource: { buffer: this.uniformBuffer }
                    }]
                });

                // Create pipeline
                const pipelineLayout = this.device.createPipelineLayout({
                    bindGroupLayouts: [bindGroupLayout]
                });

                this.pipeline = this.device.createRenderPipeline({
                    layout: pipelineLayout,
                    vertex: {
                        module: shaderModule,
                        entryPoint: 'vertexMain',
                    },
                    fragment: {
                        module: shaderModule,
                        entryPoint: 'fragmentMain',
                        targets: [{
                            format: format,
                        }],
                    },
                    primitive: {
                        topology: 'triangle-list',
                    },
                });
            }

            updateCamera() {
                if (this.activeCamera === 'orbit') {
                    const theta = this.cameraRot.theta;
                    const phi = this.cameraRot.phi;

                    this.cameraPos.x = this.cameraDistance * Math.sin(phi) * Math.cos(theta);
                    this.cameraPos.y = this.cameraDistance * Math.cos(phi);
                    this.cameraPos.z = this.cameraDistance * Math.sin(phi) * Math.sin(theta);
                } else {
                    // Free Camera Logic
                    const speed = this.freeCamera.speed * (this.freeCamera.keys.shift ? 3.0 : 1.0);
                    const rot = this.freeCamera.rot;

                    const cosY = Math.cos(rot.yaw);
                    const sinY = Math.sin(rot.yaw);
                    // Forward vector (flat on Y)
                    const fwd = { x: cosY, z: sinY };
                    // Right vector
                    const right = { x: -sinY, z: cosY };

                    if (this.freeCamera.keys.w) {
                        this.freeCamera.pos.x += fwd.x * speed;
                        this.freeCamera.pos.z += fwd.z * speed;
                    }
                    if (this.freeCamera.keys.s) {
                        this.freeCamera.pos.x -= fwd.x * speed;
                        this.freeCamera.pos.z -= fwd.z * speed;
                    }
                    if (this.freeCamera.keys.d) {
                        this.freeCamera.pos.x += right.x * speed;
                        this.freeCamera.pos.z += right.z * speed;
                    }
                    if (this.freeCamera.keys.a) {
                        this.freeCamera.pos.x -= right.x * speed;
                        this.freeCamera.pos.z -= right.z * speed;
                    }
                    if (this.freeCamera.keys.q) {
                        this.freeCamera.pos.y -= speed;
                    }
                    if (this.freeCamera.keys.e) {
                        this.freeCamera.pos.y += speed;
                    }

                    // Sync main camera pos for rendering
                    this.cameraPos.x = this.freeCamera.pos.x;
                    this.cameraPos.y = this.freeCamera.pos.y;
                    this.cameraPos.z = this.freeCamera.pos.z;
                }
            }

            updateUniforms() {
                this.updateCamera();

                const camFwd = this.vecFwd;
                const camRight = this.vecRight;
                const camUp = this.vecUp;

                if (this.activeCamera === 'orbit') {
                    // Standard Orbit Logic (Look at origin)
                    const px = this.cameraPos.x;
                    const py = this.cameraPos.y;
                    const pz = this.cameraPos.z;

                    camFwd[0] = -px; camFwd[1] = -py; camFwd[2] = -pz;
                    const len = Math.sqrt(camFwd[0] ** 2 + camFwd[1] ** 2 + camFwd[2] ** 2);
                    const invLen = 1.0 / len;
                    camFwd[0] *= invLen; camFwd[1] *= invLen; camFwd[2] *= invLen;

                    const worldUpX = 0, worldUpY = 1, worldUpZ = 0;
                    camRight[0] = camFwd[1] * worldUpZ - camFwd[2] * worldUpY;
                    camRight[1] = camFwd[2] * worldUpX - camFwd[0] * worldUpZ;
                    camRight[2] = camFwd[0] * worldUpY - camFwd[1] * worldUpX;

                    const lenR = Math.sqrt(camRight[0] ** 2 + camRight[1] ** 2 + camRight[2] ** 2);
                    const invLenR = 1.0 / lenR;
                    camRight[0] *= invLenR; camRight[1] *= invLenR; camRight[2] *= invLenR;

                    camUp[0] = camRight[1] * camFwd[2] - camRight[2] * camFwd[1];
                    camUp[1] = camRight[2] * camFwd[0] - camRight[0] * camFwd[2];
                    camUp[2] = camRight[0] * camFwd[1] - camRight[1] * camFwd[0];
                } else {
                    // Free Camera Logic (Look based on yaw/pitch)
                    const yaw = this.freeCamera.rot.yaw;
                    const pitch = this.freeCamera.rot.pitch;

                    // Precompute trig
                    const cp = Math.cos(pitch);
                    const sp = Math.sin(pitch);
                    const cy = Math.cos(yaw);
                    const sy = Math.sin(yaw);

                    // Forward vector
                    camFwd[0] = cp * cy;
                    camFwd[1] = sp;
                    camFwd[2] = cp * sy;

                    const worldUpX = 0, worldUpY = 1, worldUpZ = 0;
                    camRight[0] = camFwd[1] * worldUpZ - camFwd[2] * worldUpY;
                    camRight[1] = camFwd[2] * worldUpX - camFwd[0] * worldUpZ;
                    camRight[2] = camFwd[0] * worldUpY - camFwd[1] * worldUpX;

                    const lenR = Math.sqrt(camRight[0] ** 2 + camRight[1] ** 2 + camRight[2] ** 2);
                    const invLenR = 1.0 / lenR;
                    camRight[0] *= invLenR; camRight[1] *= invLenR; camRight[2] *= invLenR;

                    camUp[0] = camRight[1] * camFwd[2] - camRight[2] * camFwd[1];
                    camUp[1] = camRight[2] * camFwd[0] - camRight[0] * camFwd[2];
                    camUp[2] = camRight[0] * camFwd[1] - camRight[1] * camFwd[0];
                }

                const f32 = this.uF32;
                const i32 = this.uI32;

                // Pack uniforms (matching WGSL struct order)
                // We write directly into the pre-allocated buffer
                f32[0] = this.time;
                f32[1] = params.rs;
                f32[2] = params.rin;
                f32[3] = params.rout;
                i32[4] = params.maxSteps | 0;
                f32[5] = params.dPhi;
                f32[6] = params.escapeR;
                f32[7] = params.diskBoost;

                // Recalculate stars ONLY if not cached (Phase 0 partial optimization)
                // Since simYear doesn't change, we technically only need to do this once.
                if (!this.cachedStarPositions) {
                    const ORBIT_SCALE = 40.0;
                    const STATIC_YEAR = 2018.0; // Fixed year since animation is removed

                    // Helper to write star data
                    const writeStar = (star, offset, year) => {
                        const p3d = orbitalPosition3D(star, year);
                        const sA_AU = star.a_AU;
                        f32[offset] = (p3d.x / sA_AU) * ORBIT_SCALE;
                        f32[offset + 1] = (p3d.y / sA_AU) * ORBIT_SCALE;
                        f32[offset + 2] = (p3d.z / sA_AU) * ORBIT_SCALE;
                        f32[offset + 3] = params.starSize;
                        f32[offset + 4] = star.color[0];
                        f32[offset + 5] = star.color[1];
                        f32[offset + 6] = star.color[2];
                        f32[offset + 7] = params.starBoost;
                    };

                    // S2 star (offset 8)
                    writeStar(STAR_S2, 8, STATIC_YEAR);
                    // S55 star (offset 30)
                    writeStar(STAR_S55, 30, STATIC_YEAR);
                    // S38 star (offset 38)
                    writeStar(STAR_S38, 38, STATIC_YEAR);
                    // S29 star (offset 46)
                    writeStar(STAR_S29, 46, STATIC_YEAR);
                    // S4716 star (offset 54)
                    writeStar(STAR_S4716, 54, STATIC_YEAR);

                    this.cachedStarPositions = true;
                }

                // Camera Uniforms (Always dynamic)
                f32[16] = this.cameraPos.x;
                f32[17] = this.cameraPos.y;
                f32[18] = this.cameraPos.z;

                f32[19] = camFwd[0];
                f32[20] = camFwd[1];
                f32[21] = camFwd[2];

                f32[22] = camRight[0];
                f32[23] = camRight[1];
                f32[24] = camRight[2];

                f32[25] = camUp[0];
                f32[26] = camUp[1];
                f32[27] = camUp[2];

                f32[28] = Math.tan((55 * Math.PI / 180) * 0.5); // tanHalfFov
                f32[29] = this.canvas.width / this.canvas.height; // aspect

                // debugView is at the very end (index 62), viewportHeight at 63
                f32[62] = params.debugView;
                f32[63] = this.canvas.height; // viewportHeight for resolution-aware LOD

                // Write buffer
                this.device.queue.writeBuffer(this.uniformBuffer, 0, this.uniformData);

                // Update debug info for label (if needed, but label was removed)
                this._dbgStarPos = { x: f32[8], y: f32[9], z: f32[10] }; // S2 pos
                this._dbgCamFwd = { x: f32[19], y: f32[20], z: f32[21] };
                this._dbgCamRight = { x: f32[22], y: f32[23], z: f32[24] };
                this._dbgCamUp = { x: f32[25], y: f32[26], z: f32[27] };
                this._dbgTanHalfFov = f32[28];
                this._dbgAspect = f32[29];
                this._dbgCamPos = this.cameraPos;
            }

            setupInteraction() {
                this.canvas.addEventListener('mousedown', (e) => {
                    this.isDragging = true;
                    this.lastMouseX = e.clientX;
                    this.lastMouseY = e.clientY;
                });

                window.addEventListener('mouseup', () => {
                    this.isDragging = false;
                });

                // Global Keys
                window.addEventListener('keydown', (e) => {
                    const k = e.key.toLowerCase();
                    const keys = this.freeCamera.keys;

                    // Debug cycle (V key - not used for movement)
                    if (e.code === 'KeyV' && !e.repeat) {
                        params.debugView = (params.debugView + 1) % 6;
                        console.log('Debug view:', params.debugView);
                        return;
                    }

                    if (k === 'w') keys.w = true;
                    if (k === 'a') keys.a = true;
                    if (k === 's') keys.s = true;
                    if (k === 'd') keys.d = true;
                    if (k === 'q') keys.q = true;
                    if (k === 'e') keys.e = true;
                    if (e.key === 'Shift') keys.shift = true;

                    if (e.key === 'r' || e.key === 'R') {
                        this.updateCamera();
                        // ... recenter logic ... 
                    }
                });

                window.addEventListener('keyup', (e) => {
                    const k = e.key.toLowerCase();
                    const keys = this.freeCamera.keys;
                    if (k === 'w') keys.w = false;
                    if (k === 'a') keys.a = false;
                    if (k === 's') keys.s = false;
                    if (k === 'd') keys.d = false;
                    if (k === 'q') keys.q = false;
                    if (e.key === 'Shift') keys.shift = false;
                });

                this.canvas.addEventListener('mousemove', (e) => {
                    if (!this.isDragging) return;

                    const deltaX = e.clientX - this.lastMouseX;
                    const deltaY = e.clientY - this.lastMouseY;

                    if (this.activeCamera === 'orbit') {
                        this.cameraRot.theta += deltaX * 0.01;
                        this.cameraRot.phi = Math.max(0.1, Math.min(Math.PI - 0.1,
                            this.cameraRot.phi + deltaY * 0.01));
                    } else {
                        // Free Look
                        const sensitivity = 0.003;
                        this.freeCamera.rot.yaw += deltaX * sensitivity;
                        this.freeCamera.rot.pitch -= deltaY * sensitivity; // Invert Y usually feels better

                        // Clamp pitch
                        const limit = Math.PI / 2 - 0.1;
                        this.freeCamera.rot.pitch = Math.max(-limit, Math.min(limit, this.freeCamera.rot.pitch));
                    }

                    this.lastMouseX = e.clientX;
                    this.lastMouseY = e.clientY;
                });

            }

            syncZoomUI() {
                if (!this.zoomSlider || !this.zoomValueEl) return;
                this.zoomSlider.value = String(zoomTFromDistance(this.cameraDistance));
                this.zoomValueEl.textContent = this.cameraDistance.toFixed(1);
            }

            // -------------------------------------------------------
            // Unified Simulation Clock (Shared by Realtime + Offline)
            // -------------------------------------------------------
            ease01(u, type) {
                u = Math.max(0, Math.min(1, u));
                if (type === 'linear') return u;
                if (type === 'smooth') return u * u * (3.0 - 2.0 * u);          // smoothstep
                if (type === 'easeIn') return u * u;
                if (type === 'easeOut') return 1.0 - (1.0 - u) * (1.0 - u);
                return u;
            }

            segmentProgress(elapsed, segments) {
                let t = Math.max(0, elapsed);
                for (const seg of segments) {
                    if (t <= seg.seconds) {
                        const local = seg.seconds > 0 ? (t / seg.seconds) : 1.0;
                        const e = this.ease01(local, seg.ease);
                        return seg.from + (seg.to - seg.from) * e; // 0..1
                    }
                    t -= seg.seconds;
                }
                return segments.length ? segments[segments.length - 1].to : 1.0;
            }

            startCinematic() {
                this.time = 0; // Reset for reproducible renders (realtime matches offline)
                this.cinematicMode = true;
                this.cinematicElapsed = 0;
                this._forceZeroDtNextFrame = true;

                // Reset to desired start pose
                this.cameraRot.theta = 0.0;
                this.cameraRot.phi = 1.47;
                this.cameraDistance = 0.1;

                // Force full resolution for preview to match offline
                this._resScale = 1.0;
                this.onResize();

                if (this.activeCamera === 'free') this.activeCamera = 'orbit';
                this.syncZoomUI();

                // Reset live "timeline" so the next RAF starts at frame 0
                this._simStartNow = null;
                this._simFrame = 0;
            }

            tick(dt) {
                // Single simulation clock used everywhere
                dt = Math.max(0, dt);
                this.time += dt;

                // Single cinematic path (realtime + offline)
                if (this.cinematicMode) {
                    const D = this.cinematicDuration || 120.0;
                    this.cinematicElapsed = Math.min(D, this.cinematicElapsed + dt);

                    // Progress 0..1 with segment-based slow-motion
                    const u = this.segmentProgress(this.cinematicElapsed, this.cinematicSegments);

                    const startDist = 0.1;
                    const endDist = 60.0;
                    this.cameraDistance = startDist + (endDist - startDist) * u;

                    // Keep alignment
                    this.cameraRot.theta = 0.0;

                    // Avoid DOM work during offline renders
                    if (!this.isOfflineRendering && !this._offlineBusy) this.syncZoomUI();

                    if (this.cinematicElapsed >= D) this.cinematicMode = false;
                }
            }

            // -------------------------------------------------------
            // Context Restoration (after offline render)
            // -------------------------------------------------------
            restoreLiveContextConfig() {
                const format = navigator.gpu.getPreferredCanvasFormat();
                this.context.configure({
                    device: this.device,
                    format,
                    alphaMode: 'premultiplied',
                    presentMode: params.vsync ? 'fifo' : 'immediate',
                });
            }

            _reconfigureContext() {
                const format = this.presentationFormat || navigator.gpu.getPreferredCanvasFormat();
                this.context.configure({
                    device: this.device,
                    format,
                    alphaMode: 'premultiplied',
                    presentMode: params.vsync ? 'fifo' : 'immediate',
                });
            }

            // -------------------------------------------------------
            // State Save/Restore (for offline renders)
            // -------------------------------------------------------
            _deepClone(obj) {
                const sc = globalThis.structuredClone;
                return (typeof sc === 'function') ? sc(obj) : JSON.parse(JSON.stringify(obj));
            }

            _saveLiveState() {
                return {
                    time: this.time,
                    cinematicMode: this.cinematicMode,
                    cinematicElapsed: this.cinematicElapsed,
                    cameraDistance: this.cameraDistance,
                    cameraRot: { ...this.cameraRot },
                    activeCamera: this.activeCamera,
                    freeCamera: this._deepClone(this.freeCamera),
                    _resScale: this._resScale,
                    _lastNowS: this._lastNowS,
                };
            }

            _restoreLiveState(s) {
                this.time = s.time;
                this.cinematicMode = s.cinematicMode;
                this.cinematicElapsed = s.cinematicElapsed;
                this.cameraDistance = s.cameraDistance;
                this.cameraRot = s.cameraRot;
                this.activeCamera = s.activeCamera;
                this.freeCamera = s.freeCamera;
                this._resScale = s._resScale;
                this._lastNowS = s._lastNowS;
                this._forceZeroDtNextFrame = true;
            }


            // -------------------------------------------------------
            // Offline Deterministic H.264 Recorder (Perfect 60fps)
            // -------------------------------------------------------
            async recordOfflineH264({ seconds = 10, fps = 60, progressCallback = null } = {}) {
                if (this.isOfflineRendering || this._offlineBusy || this.isRecording) {
                    alert('Stop any active recording before starting offline render.');
                    return;
                }

                this.isOfflineRendering = true;
                let saved = null;

                const width = 3840;
                const height = 2160;

                dbg.capture('=== STARTING OFFLINE RENDER ===');
                dbg.capture(`Target: ${seconds}s @ ${fps}fps = ${seconds * fps} frames`);
                console.log(`Starting Offline Render: ${seconds}s @ ${fps}fps (${width}x${height})`);

                try {
                    // Save state FIRST (before any mutations)
                    saved = this._saveLiveState();

                    // 1. Lock Canvas & Reconfigure Context with opaque alpha mode
                    this.canvas.width = width;
                    this.canvas.height = height;

                    const format = navigator.gpu.getPreferredCanvasFormat();
                    this.context.configure({
                        device: this.device,
                        format,
                        alphaMode: 'opaque', // Use opaque for video capture (avoids alpha issues)
                        presentMode: 'immediate',
                    });

                    // 2. Setup Video Encoder
                    const config = {
                        codec: 'avc1.640034', // H.264 High Profile (4K)
                        width,
                        height,
                        bitrate: 80_000_000, // 80 Mbps for high quality
                        framerate: fps,
                        latencyMode: 'quality',
                        avc: { format: 'annexb' }
                    };

                    const support = await VideoEncoder.isConfigSupported(config);
                    if (!support.supported) {
                        alert('H.264 4K encoding not supported on this device/browser.');
                        return;
                    }

                    const chunks = [];
                    let wroteConfig = false; // Track if we've written SPS/PPS header

                    const encoder = new VideoEncoder({
                        output: (chunk, meta) => {
                            // Prepend SPS/PPS header data (critical for decoder initialization)
                            if (!wroteConfig && meta?.decoderConfig?.description) {
                                chunks.push(new Uint8Array(meta.decoderConfig.description));
                                wroteConfig = true;
                                dbg.capture('Wrote H.264 SPS/PPS header');
                            }
                            const data = new Uint8Array(chunk.byteLength);
                            chunk.copyTo(data);
                            chunks.push(data);
                        },
                        error: (e) => {
                            dbg.error('VideoEncoder error', { error: e.message });
                            console.error('Encoder Error:', e);
                        }
                    });

                    encoder.configure(config);

                    const totalFrames = Math.floor(seconds * fps);
                    const dt = 1 / fps;
                    const frameDurationUs = Math.round(1_000_000 / fps);

                    // Start cinematic automatically for offline render
                    this.startCinematic();

                    const startRealTime = performance.now();

                    for (let i = 0; i < totalFrames; i++) {
                        // Use unified tick()+render() pattern (matches realtime perfectly)
                        this.tick(i === 0 ? 0 : dt);
                        this.render();

                        // Wait for GPU to finish (Critical for sync)
                        await this.device.queue.onSubmittedWorkDone();

                        // Backpressure: Pause if encoder is overwhelmed
                        while (encoder.encodeQueueSize > 2) {
                            await new Promise(r => setTimeout(r, 10));
                        }

                        // Encode the frame using createImageBitmap (fixes format conversion)
                        const bitmap = await createImageBitmap(this.canvas);
                        const frame = new VideoFrame(bitmap, {
                            timestamp: i * frameDurationUs,
                            duration: frameDurationUs
                        });
                        bitmap.close();

                        encoder.encode(frame, { keyFrame: (i % fps) === 0 });
                        frame.close();

                        // Progress logging
                        if (i % 30 === 0 || i === totalFrames - 1) {
                            const elapsed = (performance.now() - startRealTime) / 1000;
                            const eta = (elapsed / (i + 1)) * (totalFrames - i - 1);
                            const msg = `Frame ${i + 1}/${totalFrames} (${((i + 1) / totalFrames * 100).toFixed(1)}%) - ETA: ${eta.toFixed(1)}s`;
                            console.log(msg);
                            dbg.capture(msg);
                            if (progressCallback) progressCallback(i + 1, totalFrames, msg);
                        }
                    }

                    // 4. Finish & Download
                    dbg.capture('Flushing encoder...');
                    console.log('Flushing encoder...');
                    await encoder.flush();
                    encoder.close();

                    const totalBytes = chunks.reduce((s, c) => s + c.byteLength, 0);
                    const sizeMB = (totalBytes / 1024 / 1024).toFixed(2);
                    const realDuration = ((performance.now() - startRealTime) / 1000).toFixed(1);

                    dbg.capture(`Render complete: ${totalFrames} frames, ${sizeMB} MB, took ${realDuration}s`);
                    console.log(`Render complete: ${totalFrames} frames, ${sizeMB} MB, took ${realDuration}s`);

                    const blob = new Blob(chunks, { type: 'video/h264' });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `blackhole_4k_${fps}fps_${Date.now()}.h264`;
                    a.click();
                    URL.revokeObjectURL(url);

                    alert(`Render Complete!\n\n${totalFrames} frames @ ${fps}fps\nFile: ${sizeMB} MB\nRender time: ${realDuration}s\n\nConvert to MP4 (fast remux):\nffmpeg -r ${fps} -i blackhole_*.h264 -c copy -movflags +faststart out.mp4\n\n(If remux fails, re-encode with):\nffmpeg -r ${fps} -i blackhole_*.h264 -c:v libx264 -crf 18 -pix_fmt yuv420p out.mp4`);
                } finally {
                    // Always restore (even on early return) - correct order: resize → configure → restore state
                    this.isOfflineRendering = false;
                    this.onResize();
                    this.restoreLiveContextConfig();
                    if (saved) this._restoreLiveState(saved);
                }
            }

            // -------------------------------------------------------
            // PNG Sequence Capture: Create Resources (rgba8unorm pipeline)
            // -------------------------------------------------------
            createCaptureResources(width, height) {
                // Create capture pipeline targeting rgba8unorm (not bgra8unorm)
                if (!this.capturePipeline) {
                    const pipelineLayout = this.device.createPipelineLayout({
                        bindGroupLayouts: [this.bindGroupLayout],
                    });

                    this.capturePipeline = this.device.createRenderPipeline({
                        layout: pipelineLayout,
                        vertex: { module: this.shaderModule, entryPoint: 'vertexMain' },
                        fragment: {
                            module: this.shaderModule,
                            entryPoint: 'fragmentMain',
                            targets: [{ format: 'rgba8unorm' }], // Correct format for PNG
                        },
                        primitive: { topology: 'triangle-list' },
                    });
                }

                // Capture texture
                if (this.captureTexture) this.captureTexture.destroy();
                this.captureTexture = this.device.createTexture({
                    size: { width, height, depthOrArrayLayers: 1 },
                    format: 'rgba8unorm',
                    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
                    label: 'Offline PNG Capture Texture',
                });

                // Capture buffer (with required row padding for WebGPU)
                this.captureBytesPerRow = width * 4;
                this.capturePaddedBytesPerRow = Math.ceil(this.captureBytesPerRow / 256) * 256;
                const bufferSize = this.capturePaddedBytesPerRow * height;

                if (this.captureBuffer) this.captureBuffer.destroy();
                this.captureBuffer = this.device.createBuffer({
                    size: bufferSize,
                    usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
                    label: 'Offline PNG Capture Buffer',
                });

                // Reusable PNG canvas and ImageData
                if (!this.pngCanvas) {
                    this.pngCanvas = new OffscreenCanvas(width, height);
                    this.pngCtx = this.pngCanvas.getContext('2d', { willReadFrequently: true });
                } else if (this.pngCanvas.width !== width || this.pngCanvas.height !== height) {
                    this.pngCanvas.width = width;
                    this.pngCanvas.height = height;
                    this.pngCtx = this.pngCanvas.getContext('2d', { willReadFrequently: true });
                }

                this.pngImageData = this.pngCtx.createImageData(width, height);
            }

            // -------------------------------------------------------
            // PNG Sequence Capture: Render one frame and return raw RGBA
            // -------------------------------------------------------
            async renderFrameRGBA(width, height) {
                this.updateUniforms();

                const encoder = this.device.createCommandEncoder({ label: 'OfflineFrameEncoder' });

                const pass = encoder.beginRenderPass({
                    colorAttachments: [{
                        view: this.captureTexture.createView(),
                        clearValue: { r: 0, g: 0, b: 0, a: 1 },
                        loadOp: 'clear',
                        storeOp: 'store',
                    }],
                });

                pass.setPipeline(this.capturePipeline);
                pass.setBindGroup(0, this.bindGroup);
                pass.draw(6, 1, 0, 0);
                pass.end();

                encoder.copyTextureToBuffer(
                    { texture: this.captureTexture },
                    {
                        buffer: this.captureBuffer,
                        bytesPerRow: this.capturePaddedBytesPerRow,
                        rowsPerImage: height,
                    },
                    { width, height, depthOrArrayLayers: 1 }
                );

                this.device.queue.submit([encoder.finish()]);

                // Readback from GPU
                await this.captureBuffer.mapAsync(GPUMapMode.READ);
                const mapped = this.captureBuffer.getMappedRange();
                const src = new Uint8Array(mapped);

                // Remove padding if needed → tightly packed RGBA
                let rgba;
                if (this.capturePaddedBytesPerRow !== this.captureBytesPerRow) {
                    rgba = new Uint8Array(this.captureBytesPerRow * height);
                    for (let row = 0; row < height; row++) {
                        const srcOff = row * this.capturePaddedBytesPerRow;
                        const dstOff = row * this.captureBytesPerRow;
                        rgba.set(src.subarray(srcOff, srcOff + this.captureBytesPerRow), dstOff);
                    }
                } else {
                    rgba = new Uint8Array(src); // copy view
                }

                this.captureBuffer.unmap();
                return rgba;
            }

            // -------------------------------------------------------
            // PNG Sequence Capture: Offline renderer with File System Access API
            // -------------------------------------------------------
            async renderOfflinePNGs({
                seconds = 5,
                fps = 60,
                width = 3840,
                height = 2160,
                progressCallback = null
            } = {}) {
                // Chrome/Edge only (File System Access API)
                if (!window.showDirectoryPicker) {
                    alert('This feature requires Chrome/Edge (File System Access API).\n\nNot available in Firefox or Safari.');
                    return;
                }

                // Guard against conflicts with other recording modes
                if (this._offlineBusy || this.isOfflineRendering || this.isRecording) {
                    alert('Stop any active recording before starting offline PNG render.');
                    return;
                }

                let dir;
                try {
                    dir = await window.showDirectoryPicker();
                } catch (e) {
                    console.log('User cancelled directory picker');
                    return;
                }

                this._offlineBusy = true;
                let saved = null;

                dbg.capture('=== STARTING OFFLINE PNG RENDER ===');
                console.log(`Starting Offline PNG Render: ${seconds}s @ ${fps}fps (${width}x${height})`);

                try {
                    // Save state FIRST (before startCinematic or canvas resize)
                    saved = this._saveLiveState();

                    this.createCaptureResources(width, height);

                    // Freeze canvas size
                    this.canvas.width = width;
                    this.canvas.height = height;

                    const totalFrames = Math.floor(seconds * fps);
                    const dt = 1.0 / fps;

                    // Start cinematic automatically for PNG render
                    this.startCinematic();

                    const startRealTime = performance.now();

                    for (let f = 0; f < totalFrames; f++) {
                        // Use unified tick() for simulation state
                        this.tick(f === 0 ? 0 : dt);

                        // Render and get RGBA data
                        const rgba = await this.renderFrameRGBA(width, height);

                        // Fill reusable ImageData
                        this.pngImageData.data.set(rgba);
                        this.pngCtx.putImageData(this.pngImageData, 0, 0);

                        // Convert to PNG blob
                        const blob = await this.pngCanvas.convertToBlob({ type: 'image/png' });

                        // Write to file
                        const name = `frame_${String(f + 1).padStart(6, '0')}.png`;
                        const handle = await dir.getFileHandle(name, { create: true });
                        const writable = await handle.createWritable();
                        await writable.write(blob);
                        await writable.close();

                        // Progress logging
                        if ((f % 10) === 0 || f === totalFrames - 1) {
                            const elapsed = (performance.now() - startRealTime) / 1000;
                            const eta = (elapsed / (f + 1)) * (totalFrames - f - 1);
                            const msg = `Frame ${f + 1}/${totalFrames} (${((f + 1) / totalFrames * 100).toFixed(1)}%) - ETA: ${eta.toFixed(1)}s`;
                            console.log(`Saved ${name} - ${msg}`);
                            dbg.capture(msg);
                            if (progressCallback) progressCallback(f + 1, totalFrames, msg);
                        }

                        // Small yield every few frames so UI doesn't appear dead
                        if ((f % 5) === 0) {
                            await new Promise(r => setTimeout(r, 0));
                        }
                    }

                    const realDuration = ((performance.now() - startRealTime) / 1000).toFixed(1);
                    dbg.capture(`PNG render complete: ${totalFrames} frames in ${realDuration}s`);
                    console.log(`PNG render complete: ${totalFrames} frames in ${realDuration}s`);

                    alert(
                        `Done: wrote ${totalFrames} PNGs in ${realDuration}s.\n\nAssemble:\nffmpeg -framerate ${fps} -i frame_%06d.png -c:v libx264 -crf 18 -pix_fmt yuv420p out.mp4`
                    );
                } finally {
                    // Always restore state (even on early exit)
                    this._offlineBusy = false;
                    this.onResize();
                    if (saved) this._restoreLiveState(saved);
                }
            }

            render() {
                const frameStart = performance.now();

                // Capture video frame at start of loop (captures previous frame front buffer)
                if (this.isRecording && this.videoEncoder) {
                    this.captureVideoFrame();
                }

                // Log every 60 frames when recording
                const shouldLogFrame = this.isRecording && this.frameNumber % 60 === 0;
                if (shouldLogFrame) {
                    dbg.frame(`Render frame #${this.frameNumber}`, {
                        pendingReads: this.pendingReads.size,
                        bufferIndex: this.bufferIndex,
                        wsState: this.ws?.readyState
                    });
                }

                // Cinematic logic moved to tick() - render() is now pure draw
                this.updateUniforms();

                let commandEncoder;
                try {
                    commandEncoder = this.device.createCommandEncoder();
                } catch (e) {
                    dbg.error('Failed to create command encoder', { error: e.message });
                    return;
                }

                // Render to display (swapchain)
                let texture, textureView;
                try {
                    texture = this.context.getCurrentTexture();
                    textureView = texture.createView();
                } catch (e) {
                    dbg.error('Failed to get current texture', { error: e.message });
                    return;
                }

                const renderPassDescriptor = {
                    colorAttachments: [{
                        view: textureView,
                        clearValue: { r: 0, g: 0, b: 0, a: 1 },
                        loadOp: 'clear',
                        storeOp: 'store',
                    }],
                };

                try {
                    const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
                    passEncoder.setPipeline(this.pipeline);
                    passEncoder.setBindGroup(0, this.bindGroup);
                    passEncoder.draw(6, 1, 0, 0);
                    passEncoder.end();

                    this.device.queue.submit([commandEncoder.finish()]);
                } catch (e) {
                    dbg.error('Render pass failed', { error: e.message, stack: e.stack });
                    return;
                }

                // Capture frame if recording
                if (this.isRecording) {
                    if (this.captureTexture) {
                        // Legacy PNG capture (slow, uses WebSocket)
                        this.captureFrame();
                    }
                }

                const frameEnd = performance.now();
                const frameTime = frameEnd - frameStart;

                // Track frame times
                this.frameTimes.push(frameTime);
                if (this.frameTimes.length > 120) {
                    this.frameTimes.shift();
                }

                // FPS counter and stats update
                this.frameCount++;
                const now = performance.now();
                if (now - this.lastFPSUpdate > 1000) {
                    this.currentFPS = Math.round(this.frameCount * 1000 / (now - this.lastFPSUpdate));

                    // Update display
                    this.updateStatsDisplay();

                    this.frameCount = 0;
                    this.lastFPSUpdate = now;
                }

                // Performance logging removed

                // Performance logging removed

                this.lastFrameTime = frameEnd;

                // Dynamic Resolution Scaling (only when NOT cinematic/offline/recording)
                if (this.frameCount > 30 && !this.cinematicMode && !this.isOfflineRendering && !this._offlineBusy && !this.isRecording) {
                    const fps = this.currentFPS;
                    const dpr = Math.min(window.devicePixelRatio, 2);
                    const w = this.canvas.clientWidth * dpr;
                    const h = this.canvas.clientHeight * dpr;

                    if (!this._resScale) this._resScale = 1.0;

                    // Only scale if trying to hit vsync target (60fps implied)
                    if (params.vsync) {
                        if (fps < 45 && this._resScale > 0.5) {
                            this._resScale -= 0.05;
                            this.resize(w, h);
                        } else if (fps >= 58 && this._resScale < 1.0) {
                            this._resScale += 0.05;
                            this.resize(w, h);
                        }
                    }
                }
            }



            async toggleRecording(btn) {
                if (this.isRecording) {
                    // Stop
                    dbg.capture('=== STOPPING RECORDING ===');
                    this.isRecording = false;

                    // Wait for all pending captures to finish
                    if (this.pendingReads.size > 0) {
                        dbg.capture(`Waiting for ${this.pendingReads.size} pending captures...`);
                        await Promise.all([...this.pendingReads]);
                    }

                    if (this.ws) {
                        this.ws.close();
                        this.ws = null;
                    }
                    // Clean up staging buffers (now safe)
                    dbg.capture('Destroying staging buffers...');
                    this.stagingBuffers.forEach((buf, i) => {
                        try {
                            buf.destroy();
                            dbg.capture(`Buffer ${i} destroyed`);
                        } catch (e) {
                            dbg.error(`Failed to destroy buffer ${i}`, { error: e.message });
                        }
                    });
                    this.stagingBuffers = [];
                    this.pendingReads.clear();

                    // Clean up capture texture
                    if (this.captureTexture) {
                        dbg.capture('Destroying capture texture...');
                        try {
                            this.captureTexture.destroy();
                        } catch (e) {
                            dbg.error('Failed to destroy capture texture', { error: e.message });
                        }
                        this.captureTexture = null;
                    }

                    dbg.capture(`Recording stopped. Total frames: ${this.frameNumber}`);
                    this.onResize();
                    btn.textContent = '⚫ Start PNG Capture';
                    btn.style.background = 'rgba(255, 50, 50, 0.2)';
                    btn.style.color = '#fff';
                    setTimeout(() => alert(`Captured ${this.frameNumber} frames to png folder.`), 100);
                } else {
                    // Start - connect to WebSocket server
                    dbg.capture('=== STARTING RECORDING ===');
                    dbg.capture('Connecting to PNG capture server on ws://localhost:8765...');

                    this.ws = new WebSocket('ws://localhost:8765');
                    this.ws.binaryType = 'arraybuffer';

                    this.ws.onopen = () => {
                        dbg.capture('Connected to PNG capture server (binary mode)');

                        // Lock resolution to 4K
                        dbg.capture('Setting canvas to 4K resolution...');
                        this.canvas.width = 3840;
                        this.canvas.height = 2160;
                        dbg.capture(`Canvas size: ${this.canvas.width}x${this.canvas.height}`);

                        // Create dedicated capture texture with rgba8unorm format
                        dbg.capture('Creating capture texture...');
                        try {
                            this.captureTexture = this.device.createTexture({
                                size: { width: this.canvas.width, height: this.canvas.height, depthOrArrayLayers: 1 },
                                format: 'rgba8unorm',  // Fixed format for PNG server
                                usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
                                label: 'Capture Texture'
                            });
                            dbg.capture('Capture texture created successfully');
                        } catch (e) {
                            dbg.error('Failed to create capture texture!', { error: e.message, stack: e.stack });
                            return;
                        }

                        // Create triple-buffered staging buffers for GPU readback
                        const bytesPerPixel = 4; // RGBA
                        const bytesPerRow = this.canvas.width * bytesPerPixel;
                        const paddedBytesPerRow = Math.ceil(bytesPerRow / 256) * 256; // GPU alignment
                        const bufferSize = paddedBytesPerRow * this.canvas.height;

                        dbg.capture('Creating staging buffers...', {
                            bytesPerRow,
                            paddedBytesPerRow,
                            bufferSize,
                            bufferSizeMB: (bufferSize / 1024 / 1024).toFixed(2)
                        });

                        try {
                            for (let i = 0; i < 3; i++) {
                                this.stagingBuffers.push(
                                    this.device.createBuffer({
                                        size: bufferSize,
                                        usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
                                        label: `Staging Buffer ${i}`
                                    })
                                );
                                dbg.capture(`Staging buffer ${i} created`);
                            }
                        } catch (e) {
                            dbg.error('Failed to create staging buffers!', { error: e.message, stack: e.stack });
                            return;
                        }

                        // Ensure capturePipeline exists for rgba8unorm format (fixes format mismatch)
                        if (!this.capturePipeline) {
                            const pipelineLayout = this.device.createPipelineLayout({
                                bindGroupLayouts: [this.bindGroupLayout],
                            });
                            this.capturePipeline = this.device.createRenderPipeline({
                                layout: pipelineLayout,
                                vertex: { module: this.shaderModule, entryPoint: 'vertexMain' },
                                fragment: {
                                    module: this.shaderModule,
                                    entryPoint: 'fragmentMain',
                                    targets: [{ format: 'rgba8unorm' }], // Match captureTexture format
                                },
                                primitive: { topology: 'triangle-list' },
                            });
                            dbg.capture('Created capturePipeline for rgba8unorm');
                        }

                        this.frameNumber = 0;
                        this.bufferIndex = 0;
                        this.pendingReads.clear();
                        this.isRecording = true;

                        dbg.capture('Recording started. Ready to capture frames.');
                        btn.textContent = '🟥 Stop PNG Capture';
                        btn.style.background = 'rgba(255, 0, 0, 0.6)';
                        btn.style.color = '#fff';
                    };

                    this.ws.onerror = (err) => {
                        dbg.error('WebSocket error connecting to capture server', { error: err });
                        alert('Failed to connect to server. Make sure png_server_simple.py is running.');
                    };

                    this.ws.onclose = () => {
                        dbg.capture('Disconnected from PNG capture server');
                    };
                }
            }

            // WebCodecs Video Recording - Hardware accelerated H.264 encoding
            async toggleVideoRecording(btn) {
                if (this.isRecording) {
                    // Stop recording
                    dbg.capture('=== STOPPING VIDEO RECORDING ===');
                    this.isRecording = false;

                    if (this.videoEncoder) {
                        dbg.capture('Flushing video encoder...');
                        await this.videoEncoder.flush();
                        this.videoEncoder.close();
                        this.videoEncoder = null;
                    }

                    const elapsed = (performance.now() - this.videoRecordingStart) / 1000;
                    const avgFps = this.frameNumber / elapsed;
                    const totalBytes = this.videoChunks.reduce((s, c) => s + c.byteLength, 0);
                    const sizeMB = (totalBytes / 1024 / 1024).toFixed(2);

                    dbg.capture(`Recording complete!`, {
                        frames: this.frameNumber,
                        duration: elapsed.toFixed(1) + 's',
                        avgFps: avgFps.toFixed(1),
                        sizeMB
                    });

                    // Create downloadable video file
                    dbg.capture('Creating video file...');
                    const blob = new Blob(this.videoChunks, { type: 'video/h264' });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `blackhole_4k_${Date.now()}.h264`;
                    a.click();
                    URL.revokeObjectURL(url);

                    this.videoChunks = [];
                    this.onResize();

                    btn.textContent = '🎬 Start 4K Video';
                    btn.style.background = 'rgba(79, 209, 197, 0.3)';
                    btn.style.color = '#4fd1c5';

                    setTimeout(() => alert(`Recorded ${this.frameNumber} frames (${elapsed.toFixed(1)}s) at ${avgFps.toFixed(1)} FPS\nFile size: ${sizeMB} MB\n\nNote: Convert .h264 to .mp4 with:\nffmpeg -framerate 60 -i blackhole_4k_*.h264 -c copy output.mp4`), 100);

                } else {
                    // Check WebCodecs support
                    if (typeof VideoEncoder === 'undefined') {
                        alert('WebCodecs not supported. Use Chrome 94+ or Edge 94+');
                        return;
                    }

                    // Configure encoder for 4K H.264
                    const config = {
                        codec: 'avc1.640034', // H.264 High Profile Level 5.2 (4K 60fps)
                        width: 3840,
                        height: 2160,
                        bitrate: 50_000_000, // 50 Mbps for high quality
                        framerate: 60,
                        latencyMode: 'realtime',
                        avc: { format: 'annexb' }
                    };

                    const support = await VideoEncoder.isConfigSupported(config);
                    if (!support.supported) {
                        alert('H.264 4K encoding not supported on this device');
                        return;
                    }

                    dbg.capture('=== STARTING VIDEO RECORDING (WebCodecs) ===');

                    // Lock to 4K resolution
                    this.canvas.width = 3840;
                    this.canvas.height = 2160;
                    dbg.capture(`Canvas set to ${this.canvas.width}x${this.canvas.height}`);

                    this.videoChunks = [];
                    this.frameNumber = 0;
                    this.videoRecordingStart = performance.now();
                    this._wroteVideoConfig = false; // Track SPS/PPS header

                    this.videoEncoder = new VideoEncoder({
                        output: (chunk, meta) => {
                            // Prepend SPS/PPS header data (critical for decoder initialization)
                            if (!this._wroteVideoConfig && meta?.decoderConfig?.description) {
                                this.videoChunks.push(new Uint8Array(meta.decoderConfig.description));
                                this._wroteVideoConfig = true;
                                dbg.capture('Wrote H.264 SPS/PPS header (realtime)');
                            }

                            const data = new Uint8Array(chunk.byteLength);
                            chunk.copyTo(data);
                            this.videoChunks.push(data);

                            // Update button with stats every 30 frames
                            if (this.frameNumber % 30 === 0) {
                                const elapsed = (performance.now() - this.videoRecordingStart) / 1000;
                                const fps = this.frameNumber / elapsed;
                                const mb = this.videoChunks.reduce((s, c) => s + c.byteLength, 0) / 1024 / 1024;
                                btn.textContent = `🔴 ${this.frameNumber}f | ${fps.toFixed(0)}fps | ${mb.toFixed(1)}MB`;
                            }
                        },
                        error: (e) => {
                            dbg.error('Video encoder error', { error: e.message });
                            console.error('VideoEncoder error:', e);
                        }
                    });

                    this.videoEncoder.configure(config);
                    this.isRecording = true;

                    dbg.capture('Video encoder configured, recording started');
                    btn.textContent = '🔴 Recording...';
                    btn.style.background = 'rgba(255, 0, 0, 0.6)';
                    btn.style.color = '#fff';
                }
            }

            // Capture current frame to video encoder
            captureVideoFrame() {
                if (!this.isRecording || !this.videoEncoder) return;

                try {
                    const videoFrame = new VideoFrame(this.canvas, {
                        timestamp: this.frameNumber * (1000000 / 60), // microseconds
                        duration: 1000000 / 60
                    });

                    this.videoEncoder.encode(videoFrame, {
                        keyFrame: this.frameNumber % 60 === 0
                    });
                    videoFrame.close();
                    this.frameNumber++;
                } catch (e) {
                    if (this.frameNumber % 60 === 0) {
                        dbg.error('Video frame capture failed', { error: e.message });
                    }
                }
            }

            async captureFrame() {
                if (!this.isRecording || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
                    if (this.frameNumber % 60 === 0) {
                        dbg.capture('captureFrame: skipped (not ready)', {
                            isRecording: this.isRecording,
                            wsExists: !!this.ws,
                            wsState: this.ws?.readyState
                        });
                    }
                    return;
                }
                if (this.stagingBuffers.length === 0 || !this.captureTexture) {
                    dbg.warn('captureFrame: skipped (no buffers or texture)');
                    return;
                }

                // Backpressure: skip frame if queue is full
                if (this.pendingReads.size >= 3) {
                    if (this.frameNumber % 30 === 0) {
                        dbg.warn('Capture queue full, dropping frame', { pendingReads: this.pendingReads.size });
                    }
                    return;
                }

                const currentFrameNumber = this.frameNumber++;

                // Detailed logging for first 10 frames and every 60th frame
                const shouldLog = currentFrameNumber < 10 || currentFrameNumber % 60 === 0;

                try {
                    const width = this.canvas.width;
                    const height = this.canvas.height;
                    const bytesPerPixel = 4;
                    const bytesPerRow = width * bytesPerPixel;
                    const paddedBytesPerRow = Math.ceil(bytesPerRow / 256) * 256;

                    // Get current staging buffer (triple buffering)
                    const bufIdx = this.bufferIndex;
                    const stagingBuffer = this.stagingBuffers[bufIdx];
                    this.bufferIndex = (this.bufferIndex + 1) % 3;

                    if (shouldLog) {
                        dbg.capture(`Capturing frame ${currentFrameNumber}`, {
                            bufferIndex: bufIdx,
                            pendingReads: this.pendingReads.size,
                            width, height
                        });
                    }

                    // Render to capture texture (rgba8unorm format)
                    let commandEncoder;
                    try {
                        commandEncoder = this.device.createCommandEncoder({ label: `Capture Encoder ${currentFrameNumber}` });
                    } catch (e) {
                        dbg.error(`Frame ${currentFrameNumber}: Failed to create command encoder`, { error: e.message });
                        return;
                    }

                    let captureView;
                    try {
                        captureView = this.captureTexture.createView();
                    } catch (e) {
                        dbg.error(`Frame ${currentFrameNumber}: Failed to create capture texture view`, { error: e.message });
                        return;
                    }

                    try {
                        const capturePass = commandEncoder.beginRenderPass({
                            colorAttachments: [{
                                view: captureView,
                                clearValue: { r: 0, g: 0, b: 0, a: 1 },
                                loadOp: 'clear',
                                storeOp: 'store',
                            }],
                        });

                        capturePass.setPipeline(this.capturePipeline); // Use rgba8unorm pipeline, not bgra8unorm
                        capturePass.setBindGroup(0, this.bindGroup);
                        capturePass.draw(6, 1, 0, 0);
                        capturePass.end();

                        // Copy capture texture to staging buffer
                        commandEncoder.copyTextureToBuffer(
                            { texture: this.captureTexture },
                            {
                                buffer: stagingBuffer,
                                bytesPerRow: paddedBytesPerRow,
                                rowsPerImage: height
                            },
                            { width, height, depthOrArrayLayers: 1 }
                        );

                        this.device.queue.submit([commandEncoder.finish()]);
                    } catch (e) {
                        dbg.error(`Frame ${currentFrameNumber}: Capture render pass failed`, { error: e.message, stack: e.stack });
                        return;
                    }

                    // Async read from GPU (track promise for backpressure)
                    const capturePromise = stagingBuffer.mapAsync(GPUMapMode.READ)
                        .then(() => {
                            if (shouldLog) {
                                dbg.capture(`Frame ${currentFrameNumber}: mapAsync completed, reading data...`);
                            }

                            const arrayBuffer = stagingBuffer.getMappedRange();
                            const pixelData = new Uint8Array(arrayBuffer);

                            // Remove padding if present
                            let finalData;
                            if (paddedBytesPerRow !== bytesPerRow) {
                                finalData = new Uint8Array(bytesPerRow * height);
                                for (let row = 0; row < height; row++) {
                                    const srcOffset = row * paddedBytesPerRow;
                                    const dstOffset = row * bytesPerRow;
                                    finalData.set(pixelData.subarray(srcOffset, srcOffset + bytesPerRow), dstOffset);
                                }
                            } else {
                                finalData = new Uint8Array(pixelData);
                            }

                            // Create binary message: [frame_number][width][height][rgba_data]
                            const header = new ArrayBuffer(12);
                            const headerView = new DataView(header);
                            headerView.setUint32(0, currentFrameNumber, true); // little-endian
                            headerView.setUint32(4, width, true);
                            headerView.setUint32(8, height, true);

                            // Combine header + pixel data
                            const message = new Uint8Array(12 + finalData.length);
                            message.set(new Uint8Array(header), 0);
                            message.set(finalData, 12);

                            // Send binary data
                            if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                                this.ws.send(message.buffer);
                                if (shouldLog) {
                                    dbg.capture(`Frame ${currentFrameNumber}: sent ${(message.length / 1024 / 1024).toFixed(2)} MB`);
                                }
                            }
                        })
                        .catch(err => {
                            dbg.error(`Frame ${currentFrameNumber}: mapAsync failed`, { error: err.message, stack: err.stack });
                        })
                        .finally(() => {
                            try {
                                stagingBuffer.unmap();
                            } catch (e) {
                                // Already unmapped, ignore
                            }
                        });

                    // Track promise for backpressure and cleanup
                    this.pendingReads.add(capturePromise);
                    capturePromise.finally(() => this.pendingReads.delete(capturePromise));

                } catch (e) {
                    dbg.error(`Frame capture error (outer)`, { error: e.message, stack: e.stack });
                }
            }

            resize(fullW, fullH) {
                // Prevent resize if recording/offline rendering to maintain fixed dimensions
                if (this.isRecording || this.isOfflineRendering || this._offlineBusy) return;

                if (!this._resScale) this._resScale = 1.0;
                const newW = Math.floor(fullW * this._resScale);
                const newH = Math.floor(fullH * this._resScale);

                if (this.canvas.width !== newW || this.canvas.height !== newH) {
                    this.canvas.width = newW;
                    this.canvas.height = newH;
                    this._reconfigureContext(); // ✅ important
                }
            }

            onResize() {
                // Prevent resize during any recording/offline rendering mode
                if (this.isRecording || this.isOfflineRendering || this._offlineBusy) return;

                const dpr = Math.min(window.devicePixelRatio, 2);
                const newW = Math.floor(this.canvas.clientWidth * dpr);
                const newH = Math.floor(this.canvas.clientHeight * dpr);

                if (this.canvas.width !== newW || this.canvas.height !== newH) {
                    this.canvas.width = newW;
                    this.canvas.height = newH;
                    this._reconfigureContext(); // ✅ important
                }

                this.updateStatsDisplay();
            }

            updateStatsDisplay() {
                if (!this.fpsEl || !this.p99El) return;

                // FPS
                this.fpsEl.textContent = `FPS: ${this.currentFPS}`;

                // P99 latency
                if (this.frameTimes.length > 0) {
                    // Copy and sort to find percentile
                    const sorted = [...this.frameTimes].sort((a, b) => a - b);
                    const idx = Math.floor(sorted.length * 0.99);
                    const p99 = sorted[Math.min(idx, sorted.length - 1)];
                    this.p99El.textContent = `P99: ${p99.toFixed(1)}ms`;

                    // Color coding
                    if (p99 > 20) this.p99El.style.color = '#ff4444'; // Red
                    else if (p99 > 16.7) this.p99El.style.color = '#ffbb33'; // Orange
                    else this.p99El.style.color = '#00cc00'; // Green
                }

                // Cam Pos
                if (this.posEl) {
                    const cx = this.cameraPos.x.toFixed(1);
                    const cy = this.cameraPos.y.toFixed(1);
                    const cz = this.cameraPos.z.toFixed(1);
                    this.posEl.textContent = `Pos: ${cx}, ${cy}, ${cz}`;
                }
            }
        }

        // Simple GUI
        function createGUI(app) {
            const container = document.createElement('div');
            container.style.cssText = `
        position: fixed; top: 12px; right: 12px;
        background: rgba(0,0,0,0.8); color: white;
        padding: 0; border-radius: 8px;
        font-size: 13px; min-width: 200px;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255,255,255,0.1);
        display: flex; flex-direction: column; overflow: hidden;
      `;

            // Helper to create a collapsible section
            function createSection(title, isExpanded) {
                const header = document.createElement('div');
                header.style.cssText = `
             padding: 10px 15px; display: flex; justify-content: space-between; align-items: center;
             cursor: pointer; background: rgba(255,255,255,0.05); user-select: none;
             border-bottom: 1px solid rgba(255,255,255,0.05);
          `;
                header.innerHTML = `<span style="font-weight:bold; font-size:12px; color:#ddd;">${title}</span> <span class="toggle">${isExpanded ? '▼' : '◀'}</span>`;

                const content = document.createElement('div');
                content.style.padding = '15px';
                content.style.display = isExpanded ? 'block' : 'none';

                header.onclick = () => {
                    const show = content.style.display === 'none';
                    content.style.display = show ? 'block' : 'none';
                    header.querySelector('.toggle').textContent = show ? '▼' : '◀';
                };

                container.appendChild(header);
                container.appendChild(content);
                return content;
            }

            // --- Section 1: Settings ---
            const settingsContent = createSection('SETTINGS', true);

            // Performance Stats (FPS/P99)
            {
                const row = document.createElement('div');
                row.style.cssText = 'display: flex; justify-content: space-between; margin-bottom: 10px; font-family: monospace; font-size: 14px;';

                app.fpsEl = document.createElement('div');
                app.fpsEl.textContent = 'FPS: --';
                app.fpsEl.style.color = '#00cc00';

                app.p99El = document.createElement('div');
                app.p99El.textContent = 'P99: --';

                row.appendChild(app.fpsEl);
                row.appendChild(app.p99El);
                settingsContent.appendChild(row);

                // Camera Position (New Row)
                const posRow = document.createElement('div');
                posRow.style.cssText = 'margin-bottom: 10px; font-family: monospace; font-size: 13px; color: #aaa;';
                app.posEl = document.createElement('div');
                app.posEl.textContent = 'Pos: 0.0, 0.0, 0.0';
                posRow.appendChild(app.posEl);
                settingsContent.appendChild(posRow);
            }

            // Stats content removed


            // Stats elements initialization removed

            // Zoom slider (log scale)
            const zoomWrapper = document.createElement('div');
            zoomWrapper.style.marginBottom = '10px';

            // Cinematic Button
            const cinBtn = document.createElement('button');
            cinBtn.textContent = '▶ Cinematic Zoom Out';
            cinBtn.style.cssText = `
           width: 100%; background: rgba(50, 150, 255, 0.2); border: 1px solid rgba(50, 150, 255, 0.5);
           color: white; padding: 6px; border-radius: 4px; cursor: pointer; margin-bottom: 12px;
           font-size: 11px; text-transform: uppercase; letter-spacing: 1px;
        `;
            cinBtn.onmouseover = () => cinBtn.style.background = 'rgba(50, 150, 255, 0.4)';
            cinBtn.onmouseout = () => cinBtn.style.background = 'rgba(50, 150, 255, 0.2)';
            cinBtn.onclick = () => {
                app.startCinematic();
            };
            settingsContent.appendChild(cinBtn);

            // PNG Capture Button
            const recBtn = document.createElement('button');
            recBtn.textContent = '⚫ Start PNG Capture';
            recBtn.style.cssText = `
           width: 100%; background: rgba(255, 50, 50, 0.2); border: 1px solid rgba(255, 50, 50, 0.5);
           color: white; padding: 6px; border-radius: 4px; cursor: pointer; margin-bottom: 5px;
           font-size: 11px; text-transform: uppercase; letter-spacing: 1px;
      `;
            recBtn.onclick = () => app.toggleRecording(recBtn);
            settingsContent.appendChild(recBtn);

            // WebCodecs Offline Video Capture Button (Perfect 4K 60fps H.264)
            const videoBtn = document.createElement('button');
            videoBtn.textContent = '🎬 Render 4K 60FPS (Offline)';
            videoBtn.style.cssText = `
           width: 100%; background: rgba(79, 209, 197, 0.3); border: 1px solid rgba(79, 209, 197, 0.6);
           color: #4fd1c5; padding: 8px; border-radius: 4px; cursor: pointer; margin-bottom: 5px;
           font-size: 12px; text-transform: uppercase; letter-spacing: 1px; font-weight: bold;
      `;
            videoBtn.onclick = async () => {
                // Disable button during render
                videoBtn.disabled = true;
                const originalText = videoBtn.textContent;
                videoBtn.textContent = '⏳ Rendering... Check Console';
                videoBtn.style.background = 'rgba(255, 165, 0, 0.4)';
                videoBtn.style.borderColor = 'orange';

                try {
                    // Render full cinematic duration (matches realtime preview)
                    await app.recordOfflineH264({
                        seconds: app.cinematicDuration,
                        fps: 60,
                        progressCallback: (frame, total, msg) => {
                            videoBtn.textContent = `🔴 ${msg}`;
                        }
                    });
                } finally {
                    videoBtn.disabled = false;
                    videoBtn.textContent = originalText;
                    videoBtn.style.background = 'rgba(79, 209, 197, 0.3)';
                    videoBtn.style.borderColor = 'rgba(79, 209, 197, 0.6)';
                }
            };
            settingsContent.appendChild(videoBtn);

            // Help Text for Video Capture
            const videoHelp = document.createElement('div');
            videoHelp.textContent = '⚡ OFFLINE mode: Perfect 60fps, may take longer than real-time. Output: .h264 → use ffmpeg.';
            videoHelp.style.cssText = 'color: #4fd1c5; font-size: 10px; margin-bottom: 8px; font-style: italic;';
            settingsContent.appendChild(videoHelp);

            // Memory warning for long recordings
            const memWarning = document.createElement('div');
            memWarning.textContent = '⚠️ 180s @ 4K60 = ~1.8GB RAM. For long recordings, reduce duration to 30-60s or lower bitrate.';
            memWarning.style.cssText = 'color: #ff9800; font-size: 9px; margin-bottom: 8px; font-style: italic; line-height: 1.3;';
            settingsContent.appendChild(memWarning);

            // PNG Sequence Capture Button (VFX-style, highest quality)
            const pngBtn = document.createElement('button');
            pngBtn.textContent = '🎞 Render Offline PNGs (4K)';
            pngBtn.style.cssText = `
           width: 100%; background: rgba(255, 215, 0, 0.2); border: 1px solid rgba(255, 215, 0, 0.5);
           color: #ffd700; padding: 8px; border-radius: 4px; cursor: pointer; margin-bottom: 5px;
           font-size: 12px; text-transform: uppercase; letter-spacing: 1px; font-weight: bold;
      `;
            pngBtn.onclick = async () => {
                pngBtn.disabled = true;
                const originalText = pngBtn.textContent;
                pngBtn.textContent = '⏳ Select output folder...';

                try {
                    await app.renderOfflinePNGs({
                        seconds: app.cinematicDuration, // Full cinematic (matches realtime)
                        fps: 60,
                        width: 3840,
                        height: 2160,
                        progressCallback: (frame, total, msg) => {
                            pngBtn.textContent = `🔴 ${msg}`;
                        }
                    });
                } finally {
                    pngBtn.disabled = false;
                    pngBtn.textContent = originalText;
                }
            };
            settingsContent.appendChild(pngBtn);

            // Help Text for PNG Capture
            const pngHelp = document.createElement('div');
            pngHelp.textContent = '📁 VFX workflow: Lossless PNGs to folder. Chrome/Edge only. 4K PNGs are 2-10 MB each!';
            pngHelp.style.cssText = 'color: #ffd700; font-size: 10px; margin-bottom: 12px; font-style: italic;';
            settingsContent.appendChild(pngHelp);

            // Help Text for PNG Capture (legacy)
            const recHelp = document.createElement('div');
            recHelp.textContent = '📁 PNG mode: Slow, requires png_server_simple.py (legacy)';
            recHelp.style.cssText = 'color: #666; font-size: 9px; margin-bottom: 12px; font-style: italic;';
            settingsContent.appendChild(recHelp);
            {
                const wrapper = document.createElement('div');
                wrapper.style.marginBottom = '10px';

                const label = document.createElement('div');
                label.style.cssText = 'margin-bottom: 4px; font-size: 11px; opacity: 0.8; display: flex; justify-content: space-between; align-items: center;';
                label.innerHTML = '<span>Zoom</span>';

                const zoomEl = document.createElement('span');
                zoomEl.style.cssText = 'font-size: 11px; color: #4fd1c5; min-width: 52px; text-align: right;';
                label.appendChild(zoomEl);

                const input = document.createElement('input');
                input.type = 'range';
                input.min = '0'; input.max = '1'; input.step = '0.001';
                input.style.width = '100%';
                input.value = zoomTFromDistance(app.cameraDistance);

                wrapper.appendChild(label);
                wrapper.appendChild(input);
                settingsContent.appendChild(wrapper);

                input.addEventListener('input', (e) => {
                    const t = parseFloat(e.target.value);
                    app.cameraDistance = zoomDistanceFromT(t);
                    app.syncZoomUI();
                });

                app.zoomSlider = input;
                app.zoomValueEl = zoomEl;
                app.syncZoomUI();
            }

            function addButton(label, onClick) {
                const btn = document.createElement('button');
                btn.textContent = label;
                btn.style.cssText = `
          width: 100%;
          margin: 6px 0 12px 0;
          padding: 8px 10px;
          border-radius: 6px;
          border: 1px solid rgba(79, 209, 197, 0.45);
          background: rgba(79, 209, 197, 0.18);
          color: #bff7f0;
          cursor: pointer;
          font-size: 12px;
          font-weight: 600;
        `;
                btn.addEventListener('click', onClick);
                settingsContent.appendChild(btn);
                return btn;
            }

            function addSlider(label, paramKey, min, max, step) {
                const wrapper = document.createElement('div');
                wrapper.style.marginBottom = '10px';

                const topRow = document.createElement('div');
                topRow.style.display = 'flex';
                topRow.style.justifyContent = 'space-between';
                topRow.style.cssText = 'margin-bottom: 4px; font-size: 11px; opacity: 0.8; display: flex; justify-content: space-between; align-items: center;';
                topRow.innerHTML = `<span>${label}</span>`;

                const valEl = document.createElement('span');
                valEl.style.cssText = 'font-size: 11px; color: #4fd1c5; min-width: 52px; text-align: right;';
                valEl.textContent = params[paramKey].toFixed(2);
                topRow.appendChild(valEl);

                const input = document.createElement('input');
                input.type = 'range';
                input.min = min; input.max = max; input.step = step;
                input.style.width = '100%';
                input.value = params[paramKey];

                input.addEventListener('input', (e) => {
                    params[paramKey] = parseFloat(e.target.value);
                    valEl.textContent = params[paramKey].toFixed(2);

                    // Stats update removed
                });

                wrapper.appendChild(topRow);
                wrapper.appendChild(input);
                settingsContent.appendChild(wrapper);
            }

            // Camera Mode Toggle
            const camBtn = addButton('🎥 Mode: Orbit', () => {
                if (app.activeCamera === 'orbit') {
                    app.activeCamera = 'free';
                    camBtn.textContent = '🎥 Mode: Cinematic (WASD)';
                    camBtn.style.color = '#ffd93d';
                    camBtn.style.borderColor = '#ffd93d';

                    // Sync free cam to current orbital pos
                    app.freeCamera.pos = { ...app.cameraPos };

                    // Look at logic: simple look back at origin
                    const p = app.freeCamera.pos;
                    const dx = -p.x, dy = -p.y, dz = -p.z;
                    app.freeCamera.rot.yaw = Math.atan2(dz, dx);
                    app.freeCamera.rot.pitch = Math.asin(dy / Math.sqrt(dx * dx + dy * dy + dz * dz));

                } else {
                    app.activeCamera = 'orbit';
                    camBtn.textContent = '🎥 Mode: Orbit';
                    camBtn.style.color = '#bff7f0';
                    camBtn.style.borderColor = 'rgba(79, 209, 197, 0.45)';
                }
            });

            // --- Cinematic Presets ---
            const presetTitle = document.createElement('div');
            presetTitle.textContent = 'Cinematic Presets';
            presetTitle.style.cssText = 'font-weight: bold; margin: 15px 0 5px 0; font-size: 13px; color: #ffd93d;';
            settingsContent.appendChild(presetTitle);

            function applyPreset(pos, rot) {
                app.activeCamera = 'free';
                camBtn.textContent = '🎥 Mode: Cinematic (WASD)';
                camBtn.style.color = '#ffd93d';
                camBtn.style.borderColor = '#ffd93d';

                app.freeCamera.pos = { ...pos };
                app.freeCamera.rot = { ...rot };
            }

            const grid = document.createElement('div');
            grid.style.cssText = 'display: grid; grid-template-columns: 1fr 1fr; gap: 5px; margin-bottom: 10px;';
            settingsContent.appendChild(grid);

            function addPip(label, p, r) {
                const btn = document.createElement('button');
                btn.textContent = label;
                btn.style.cssText = `
           padding: 6px 2px; border-radius: 4px;
           border: 1px solid rgba(255,255,255,0.2); background: rgba(0,0,0,0.3);
           color: #eee; cursor: pointer; font-size: 10px;
         `;
                btn.onclick = () => applyPreset(p, r);
                grid.appendChild(btn);
            }

            // 1. Hero Shot: Classic 3/4 view, slightly elevatd
            addPip('Hero Shot', { x: 8.5, y: 3.5, z: 12.0 }, { yaw: -2.5, pitch: -0.25 });

            // 2. The Abyss: Low angle, looking up at the shadow
            addPip('The Abyss', { x: 0.0, y: -2.0, z: 8.0 }, { yaw: -1.57, pitch: 0.25 });

            // 3. Edge of Time: The classic edge-on view (Gargantua style)
            addPip('Edge of Time', { x: 0.0, y: 0.8, z: 22.0 }, { yaw: -1.57, pitch: -0.05 });

            // 4. Into The Void: Dangerously close to the photon sphere
            addPip('Into The Void', { x: 0.0, y: 0.0, z: 3.5 }, { yaw: -1.57, pitch: 0.0 });

            addButton('Reset View (Show Black Hole)', () => {
                params.debugView = 0;
                // yearsPerSecond removed
                params.starSize = 1.0; // World size
                params.starBoost = 2.0;
                params.screenOrbitRadius = 0.35;

                app.activeCamera = 'orbit';
                app.cameraDistance = 12.5;
                app.cameraRot.theta = 0;
                app.cameraRot.phi = 0.3;
                app.syncZoomUI();

                // Recenter star logic removed
            });

            addSlider('Event Horizon', 'rs', 0.2, 3.0, 0.01);
            addSlider('Inner Disk', 'rin', 1.1, 10.0, 0.1);
            addSlider('Outer Disk', 'rout', 5.0, 60.0, 1.0);
            addSlider('Quality', 'maxSteps', 40, 300, 10);
            addSlider('Brightness', 'diskBoost', 0.1, 4.0, 0.1);
            // Years / Second slider removed
            addSlider('Debug View', 'debugView', 0, 5, 1);

            // VSync Toggle
            {
                const wrapper = document.createElement('div');
                wrapper.style.marginBottom = '10px';

                const label = document.createElement('label');
                label.style.cssText = 'font-size: 11px; color: #ccc; display: flex; align-items: center; cursor: pointer;';

                const checkbox = document.createElement('input');
                checkbox.type = 'checkbox';
                checkbox.checked = params.vsync;
                checkbox.style.marginRight = '8px';

                label.appendChild(checkbox);
                label.appendChild(document.createTextNode('VSync'));
                wrapper.appendChild(label);
                settingsContent.appendChild(wrapper);

                checkbox.addEventListener('change', (e) => {
                    params.vsync = e.target.checked;
                    // Reconfigure context to apply presentMode change
                    const format = navigator.gpu.getPreferredCanvasFormat();
                    app.context.configure({
                        device: app.device,
                        format: format,
                        alphaMode: 'premultiplied',
                        presentMode: params.vsync ? 'fifo' : 'immediate',
                    });
                });
            }

            // Stats binding removed

            document.body.appendChild(container);
        }

        // Main
        async function main() {
            dbg.info('=== main() STARTING ===');
            try {
                dbg.info('Creating canvas element...');
                const canvas = document.createElement('canvas');
                canvas.style.width = '100%';
                canvas.style.height = '100%';
                canvas.style.display = 'block';
                mount.appendChild(canvas);
                dbg.info('Canvas appended to mount');

                dbg.info('Creating WebGPUBlackHole instance...');
                const app = new WebGPUBlackHole(canvas);

                dbg.info('Initializing WebGPU...');
                await app.init();
                dbg.info('WebGPU initialized successfully');

                dbg.info('Creating GUI...');
                createGUI(app);
                dbg.info('GUI created');

                window.addEventListener('resize', () => app.onResize());

                const SIM_FPS = 60;
                const FIXED_DT = 1 / SIM_FPS;

                function animate(now) {
                    // Skip real-time loop during offline rendering (H.264 or PNG)
                    if (app.isOfflineRendering || app._offlineBusy) {
                        requestAnimationFrame(animate);
                        return;
                    }

                    // Initialize timeline start on first frame (or after resets)
                    if (app._simStartNow == null) {
                        app._simStartNow = now;
                        app._simFrame = 0;
                    }

                    // How many sim frames SHOULD have happened by now?
                    const targetFrame = Math.floor(((now - app._simStartNow) / 1000) * SIM_FPS);

                    // Catch up (cap to avoid spiral-of-death)
                    let steps = targetFrame - app._simFrame;
                    const MAX_CATCHUP = 5;
                    steps = Math.min(Math.max(0, steps), MAX_CATCHUP);

                    for (let i = 0; i < steps; i++) {
                        app.tick(FIXED_DT);
                        app._simFrame++;
                    }

                    // Render current state
                    app.render();

                    requestAnimationFrame(animate);
                }

                // Start animation loop
                requestAnimationFrame(animate);

                loader.style.opacity = '0';
                setTimeout(() => loader.remove(), 500);
                dbg.info('=== main() COMPLETE - Animation loop started ===');

            } catch (err) {
                dbg.error('WebGPU initialization failed!', {
                    message: err.message,
                    stack: err.stack
                });
                loader.innerHTML = `
          <div class="error">
            <h2>WebGPU Failed to Initialize</h2>
            <p>${err.message}</p>
            <p style="margin-top: 20px;">
              <a href="?webgl">Try WebGL version instead</a>
            </p>
          </div>
        `;
            }
        }

        dbg.info('Calling main()...');
        main();
    </script>
</body>

</html>